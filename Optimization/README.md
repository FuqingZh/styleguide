## Principle
下面给你一份“通用提速清单”。不局限于 R / Docker，放之四海皆准；按影响力从大到小排。

# 优化金字塔（由上到下做）

1. **先量后改（Profiling）**

   * 只优化“最慢 20% 的代码”。
   * 用合适的 profiler：`perf/flamegraph`(系统)、`cProfile`/`py-spy`(Python)、`Rprof`/`profvis`(R)。
   * 打点计时：关键阶段 `TIC/TOC`、I/O、网络、CPU/内存占用。

2. **算法与数据结构**（最大杠杆）

   * 复杂度从 O(n²) → O(n log n) / O(n)。
   * 选对数据结构：哈希/索引、稀疏矩阵、位图、布隆过滤器。
   * 预排序 + 二分/合并而非笛卡尔/全表扫描。

3. **数据布局与格式**

   * **列式**优先（Parquet/Arrow/Feather），只读所需列。
   * 分区、分桶、建立索引；避免无谓的宽表 JOIN。
   * 合理类型（`int32/float32` 够用就别用 64 位）。

4. **向量化与“下沉到 C”**

   * 用向量化/批处理替代“逐行/逐对象循环”。
   * 调用高性能库：BLAS/LAPACK、Arrow、SIMD 内核。
   * 热点函数改为 JIT/本地扩展（Numba、Cython、Rcpp）。

5. **并发与并行**

   * 任务并行：多进程/多机；数据并行：按块/按键分区。
   * 控制线程池：`OMP_NUM_THREADS/MKL_NUM_THREADS/OPENBLAS_NUM_THREADS`，避免**过度并发**（线程互抢更慢）。
   * 异步 I/O、流水线化（生产者-消费者）。

6. **I/O 与数据搬运**

   * **把数据搬到计算附近**：尽量用本地 NVMe / tmpfs；减少跨网络反复读写。
   * 压缩与并行压缩（`pigz`）；批量读写（大块/列裁剪）。
   * 缓存与复用（结果缓存、落地中间件、memoization）。

7. **内存与拷贝**

   * **零拷贝/就地修改**：R 的 `data.table`、Python 的 `memoryview`。
   * 预分配而非反复 `append`；避免中间大对象。
   * 注意 **NUMA**、局部性、避免假共享（按块处理）。

8. **容器/运行时配置**

   * 资源：`--cpus`、`--memory`、`--shm-size`、`--ulimit nofile`。
   * 线程库与 BLAS：确保和宿主一致并设置好线程数。
   * 挂载：把**热数据**绑到本地盘或 `tmpfs`，少走 overlay 层；`-v ...:ro` 可启用页缓存复用。
   * 避免“老版本 + 未字节编译”环境；启用 JIT/字节码（R 的 `compiler`、JVM 的 `-server`）。

9. **硬件/系统**

   * 用 NVMe/SSD；合适的 RAID/文件系统（ext4/xfs），合适的挂载选项。
   * CPU 频率治理（性能模式）、固定核心/亲和性（`taskset`）、NUMA 绑核绑内存（`numactl`）。
   * 大页/透明大页配置、网络栈调优（如果有分布式）。

10. **工程与流程**

* 基准 + 回归测试，避免“优化把结果改坏”。
* 可重复环境（锁定依赖/镜像标签）；蓝绿对比。
* 记录实验：参数、版本、硬件、数据切片、结果。

---

## 各语言/工具的常见“快招”

* **R**：`data.table` 原地操作；避免 `rowwise()`；矩阵/向量化；`Rcpp`；安装时字节编译；选用 OpenBLAS/MKL。
* **Python**：`numpy/polars/pyarrow` 向量化；Numba/Cython；多进程（避开 GIL）；尽量别用逐行 `apply`。
* **SQL/大数据**：谓词下推、列裁剪、分区裁剪、广播 JOIN；Parquet+ZSTD；合理并行度与 shuffle。
* **Shell/系统**：并行 `xargs -P`/`GNU parallel`；`pigz`；`rsync` + 校验；`dd bs=` 合理块。

---

## 快速诊断清单（你这次案例的启发）

1. **复现实验**：同数据、同参数，切换“本机 vs 容器”，打点时间线。
2. **确认约束**：cgroup 资源、`/dev/shm`、ulimit、挂载介质（本地盘还是远程存储）。
3. **看线程**：是否过度多线程、库间线程互抢。
4. **看版本**：R/包版本、是否 JIT/字节编译、BLAS 实现。
5. **改写热点**：把“逐行 t.test”改为矢量化/矩阵统计（本案 60×）。
6. **数据就近**：必要时把热文件预拷到容器本地或 `tmpfs`。

---

## 何时该“停手”

* 已达成 SLA/目标；再优化收益 < 成本。
* 优化风险高（稳定性/可维护性下降）；
* 需要系统性重构（记入技术债计划，而非临时硬上）。

需要的话，我可以把这份清单改成一页式 PDF 或做成你团队的“性能诊断手册（模板 + 命令集）”。

## R
### tidyverse
I/O 是 **Input/Output（输入/输出）** 的缩写，指程序与外部世界之间的数据交换。简单说：**读进来**叫输入（Input），**写出去**叫输出（Output）。

### 常见 I/O 场景

* **磁盘/文件**：读写 CSV/TSV、Parquet、Excel 等。
* **网络**：下载/上传数据、访问数据库或对象存储。
* **终端/日志**：打印到屏幕、写日志文件。
* **进程间通信**：管道、套接字、共享内存（/dev/shm）。

### 关键指标

* **吞吐量（Throughput）**：每秒能传多少数据（MB/s、GB/s）。
* **时延（Latency）**：一次读/写的等待时间（毫秒）。
* **IOPS**：每秒处理多少次 I/O 操作（很多小文件时重要）。

### 和你这次问题的关系

* 你脚本的“读大表（fread）/写结果”属于**磁盘 I/O**；
* 在容器里把临时目录设为 `/dev/shm` 会使用**内存文件系统**（更快，但受 `--shm-size` 限制）；
* 从远端/分布式存储（如 CephFS）读数据也属于 I/O，通常**带宽/时延**比本地盘差一些。

### 何时是 I/O 瓶颈？

* CPU 占用很低，但总耗时很长；
* 大量等待读/写；`iostat`, `pidstat -d`, `dstat` 显示磁盘或网络很忙。

### 常用加速思路

* **更快格式**：读 CSV 换成 Parquet/Arrow；用 `fread()`/`vroom()` 等并行读。
* **少搬运**：只读需要的列/行；批量写、减少小文件。
* **更快介质**：把中间文件放到 SSD 或 `/dev/shm`；合理增大 `--shm-size`。
* **并行与缓存**：开启多线程读、利用 OS 缓存；网络场景尽量就近（本地化数据）。




