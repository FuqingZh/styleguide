# 《Design Skeleton：一种跨领域的系统建构方法论（v1.0）》

## 第 0 章 · 序：混乱之中浮现的骨架

现实中的系统瓦解，往往并不是因为缺少工具，而是因为缺少“结构”。

为了说明这一点，让我们从三个看似毫不相关的场景开始。

------

### （一）生物信息学实验室：一个流程在凌晨崩溃

凌晨三点，一个蛋白质组学流程再次失败。
 日志文件满是乱码，路径不一致，文件在不同阶段被覆盖，容器版本错配，结果目录结构跟上一个项目完全不同。
 技师疲于奔命，只能一遍遍地“试错”，依赖记忆和直觉。

这里的问题不是“少了某个工具”，也不是“参数没调好”。
 真正的问题是：

> **流程语义不清晰、运行结构不稳定、工具层无法替换。**

本质上，系统没有“骨架”。

------

### （二）乌克兰前线：志愿者通信网络在关键时刻断裂

在另一个世界，一个志愿者团队试图把战区现场的需求（药品、撤离、坐标）送到后方支援组。
 然而某个晚上，前线的通信突然中断。志愿者只能依赖零散的电话、截图、口口相传的信息。

不是因为没有设备，也不是因为没有人力。
 真实的问题是：

> **缺少节点定义、缺少行动路径、缺少最小可运作的语义系统。**

工具层（手机、App、热点）被摧毁时，整个行动体系随之瓦解。

是骨架缺失，而非工具缺失。

------

### （三）一段关系：误解从何而生？

两个人反复争吵，明明都有善意，却走向疏离。
 他们以为问题出在“表达方式”、“态度”、“冷淡的回复”。
 但深层结构常常是：

> **语义层失序：彼此对关系的“假设、角色、需求”未被显化。
>
> 运行层错配：沟通节奏、修复机制、冲突处理方式不一致。
>
> 工具层混乱：讯息、语气、节日仪式被误当成核心。**

在情感的世界里，“工具误当语义，运行滞后语义”也会导致系统崩溃。

------

### 这三个场景——科研系统、战区系统、情感系统——为什么可以在同一本书中出现？

因为它们是同一种结构的三种面貌。

当代世界的复杂性让我们误以为每个领域都需要不同的方法：
 科研需要工程方法；
 战区需要应急协调；
 关系需要心理学；
 国家需要政治学；
 行动系统需要组织理论。

但如果我们从系统结构本身观察，会发现：

> **所有稳定的系统，都建立在同一组三层骨架之上。**
>
> **所有失败的系统，都是这三层骨架被混淆、折断或替代所导致。**

我们称它为：

#### Design Skeleton（设计骨架）

由三部分构成：

1. **语义层（Semantics）——系统是什么？由哪些节点构成？
2. 运行层（Runtime）——系统如何活动？如何组织流程？如何处理失败？
3. 工具层（Tools）——用什么技术、仪式、设备来实现？**

在蛋白流程里，这是：

- 语义：Raw → Search → Quant → Protein → Diff
- 运行：目录结构、错误恢复、Meta 信息
- 工具：DIA-NN、MaxQuant、R、Python、容器等

在战区通信里：

- 语义：信息节点 → 验证 → 调度 → 行动
- 运行：传输频率、优先级、失败回退
- 工具：手机、电台、卫星、Mesh

在关系里：

- 语义：我是谁？我们是什么？需求是什么？
- 运行：节奏、沟通、冲突修复
- 工具：消息、语气、礼物、见面方式

尽管材料不同，但骨架是同一个。

------

#### 但本书并不是“发现了一个永恒不变的大原理”。

我们必须强调一个立场：

### ******我们不是柏拉图式地宣称****“骨架是理念本体”。

我们也不构建黑格尔式的闭合体系。**

我们采取的是：

### **后康德 + 工程实践主义 + 开放结构论**：

- 我们承认我们的理论源自有限的人类实践
- 它只是归纳结构，而不是宇宙的形而上真理
- 我们给出方法、而非终极公式
- 我们保留“开放性”与“未来可变化的入口”
- 我们避免齐泽克式的碎片化
- 我们也避免工程白皮书式的收缩视野

换句话说：

> **本书描述的是“如何构建系统的能力”，
> 而不是“系统最终应该是什么”。**

理论来自实践，
 但又能反过来指导实践。

它不是一条“完整的道路”，
 而是一把“能劈开混乱的刀”。

------

### **Design Skeleton 的目标**

本书的目标不是教你写代码，不是教你做 NGO，不是教你建立关系系统。

我们的目标是：

> **让你能够在世界任何地方、任何领域、任何制度、任何资源条件下，
> 从混乱中建起结构，从零开始设计一个系统，从局部的失败中找到整体的骨架。**

你可以用它：

- 重构蛋白质组学流程
- 构建 NGO 信息流
- 在乌克兰做志愿行动
- 建立非洲基层项目
- 设计国家级的数据平台
- 甚至构建你自己的“存在性生活计划”

所有系统都可以通过同一套方法解构、重构、再生成。

------

### **这就是第 0 章的意义：**

世界看似多样而混乱，
 但建构的路径并非不存在。

当我们看穿混乱背后的结构，
 系统就能被重建，能力就能被迁移，
 而主体的行动，也终于有了落脚点。

------

## 第 1 章 · Skeleton 的四大基础操作

> 在谈论任何“骨架”之前，我们必须先回答：
> **你要给谁搭骨架？问题到底是什么？
> 它可以被拆到什么粒度？被哪些硬约束锁死？
> 如果从零开始，你会怎么设计？**

本章讨论的是 **四个最基础、最底层的动作**。
 不管你是在重构蛋白流程，还是在战区搭一套志愿者信息系统，还是在整理自己的人生结构，它们都必须先发生：

1. **Problem Definition（问题定义）**
2. **Atomic Decomposition（原子化分解）**
3. **Physical Constraints（物理约束识别）**
4. **Zero-Based Optimal Architecture（零基最佳结构）**

这四步不是“工具包”，而是一种 **思考姿态**。
 它们帮助你从现实的混乱里，挖出可以承受未来变化的结构。

------

### **1.1 Problem Definition：先把问题从噪声中切出来**

#### 1.1.1 什么叫“问题定义”，什么又不是？

许多系统从一开始就失败，原因不是技术，而是 **定义错了问题**。

- 生信里常见的假问题：
    “这个流程太慢了，我们换一个更快的软件吧。”
    真问题往往是：
    **“当前 IO 与中间结果结构混乱，导致无法并行与缓存。”**
- 战区志愿系统里常见的假问题：
    “我们需要更快的手机、更好的卫星网络。”
    真问题更可能是：
    **“没有明确的信息节点、优先级与确认机制，信息被噪声淹没。”**
- 关系里常见的假问题：
    “他/她为什么总是晚回消息？”
    真问题也许是：
    **“双方对关系的角色与期待没有任何显化过。”**

一个问题被定义错了，后面的分解、优化、工具选择，全都只是在堆砌噪声。

**Problem Definition 的任务就是：
 从一堆抱怨、症状、工具偏好、历史路径依赖中，把“真正的问题”切出来。**

#### 1.1.2 一个简单的检测方式：问三遍“如果这个问题解决了，会发生什么？”

举个非常具体的例子。

> 场景：你觉得“蛋白流程太慢，必须加速”。

问第一遍：

> 如果“流程变快了”，会发生什么？
> —— “客户能更快拿到结果。”

再问：

> 客户晚两天拿到结果，真的构成致命问题吗？
> —— “也许不是致命的，但我们 debug 非常痛苦，任何一步出错都要重跑。”

再问：

> 如果把“debug 需要重跑整个流程”这个问题解决了，你还会这么在意“绝对运行时间”吗？
> —— “好像不会。只要能从中间接着跑，慢一点也能接受。”

这时，真正的问题从“流程太慢”变成了：

> **“流程缺少可恢复性与中间状态管理，导致错误成本过高。”**

这才是可以设计骨架的问题；前者只是情绪化的抱怨。

#### 1.1.3 三个维度过滤掉伪问题

你可以用三个过滤问题的维度：

1. **这是症状还是结构？**
    - “慢”、“卡”、“乱”、“吵”、“不回消息” ≈ 症状
    - “没有缓存结构”、“没有优先级队列”、“没有确认机制”、“没有冲突修复流程” ≈ 结构
2. **这是工具偏好还是必要条件？**
    - “一定要用 R / Python / 某框架 / 某 IM 软件” ≈ 工具偏好
    - “需要可重放日志”、“需要离线也可运行”、“需要端到端可追踪” ≈ 必要条件
3. **它是否能被写成一个“条件句”？**
    - “如果 X 改变，系统就会整体变得更稳/更清晰/更可控。”
    - 写不出这样的条件句，说明你还没抓住问题核心。

------

### **1.2 Atomic Decomposition：把系统拆到“最小不可再分的单元”**

当你真正抓住了问题，下一步不是立刻“设计解决方案”，而是：

> **把系统拆成一粒粒最小的单位——原子（atom）。**

这个过程叫 **Atomic Decomposition**。
 它有点像做手术之前，先要搞清楚肌肉、神经、血管的基本结构，而不是直接拿刀乱砍。

##### 1.2.1 原子不是“功能模块”，而是“最小事件 / 最小对象”

- 在 heatmap 中，真正的原子不是“图”，也不是“行/列”，而是：
    - 一个具体的位置 `(i, j)`
    - 一个值 `v`
    - 一个编码函数 `f(v)`（把值映射成颜色）
    - 一个排序规则 `P` / `Q`
- 在蛋白流程中，原子不是“Search 模块”、“Quant 模块”，而是：
    - “一个 RAW 文件的处理任务”
    - “一条 PSM 记录”
    - “一行 protein abundance”
    - “一次差异检验”
- 在战区志愿系统中，原子不是“项目”、“任务”，而是：
    - “一条带坐标的求助信息”
    - “一个可以执行行动的单元（人/车/无人机）”
    - “一次确认（ack）”
- 在关系中，原子也许是：
    - “一个具体的需求表达”
    - “一个具体的回应”
    - “一次冲突中的 micro action（挂断、沉默、转移话题）”

**原子的核心标准是：**

1. 不能再分了，再分就失去意义；
2. 可以被重复使用、排列组合；
3. 可以在不同系统中扮演相同的结构角色。

##### 1.2.2 为什么一定要拆到原子级别？

因为如果你只从“模块”层思考——

- “Search 模块”
- “Quant 模块”
- “Report 模块”

——你会被现有软件的模块划分绑架。

但如果你从原子层思考，你可以问更本质的问题：

- 原子之间的流动路径合理吗？
- 是否有原子在不同环节被重复加工？
- 是否有原子本来就不应该存在？
- 是否有某种原子没有被显化（比如“失败状态”）？

在战区系统里，从“原子”出发，你会把重点放在：

- 每一条信息是否被唯一识别？
- 每一次“动作”是否有明确承接原子？
- 是否存在大量“游离原子”（没人接、没人确认的信息）？

这和单纯说“我们需要一个更强大的指挥系统”是完全不同的。

##### 1.2.3 一个简单的实践方法：写出“系统原子清单表”

你可以强迫自己做一件具体的事：

> 打开一个表格，写标题：
> **“这个系统的原子是什么？”**

然后逐条写：

- 对蛋白流程：
    - RAW 文件、谱图、PSM、蛋白、样本、对比、检验结果、FDR 标记、plot 点
- 对战区信息系统：
    - 信息条目、坐标点、行动单元、风险标记、时间戳、确认记录
- 对关系：
    - 需求句子、边界声明、承诺、违背、修复动作

当你能清晰列出 10–30 个原子，你已经比 90% 的人更接近“可设计”的世界了。

------

## **1.3 Physical Constraints：承认系统无法绕过的物理墙**

在定义了问题、拆出了原子之后，第三步不是天马行空地拼方案，而是：

> **先找出那些“你无论多聪明都绕不过去的约束”。**

这就是 **Physical Constraints（物理约束）**。
 它们不是你喜欢不喜欢的问题，而是你必须面对的墙。

### 1.3.1 物理约束不只是“物理定律”，还包括这些：

1. **资源约束**
    - CPU / 内存 / IO / 带宽 / 磁盘 / 设备数量
    - 人力、时间、注意力
2. **环境约束**
    - 无法稳定联网
    - 电力不稳
    - 不能信任国家机构 / ISP
    - 法律、审查、暴力威胁
3. **认知/心理约束**
    - 人类无法同时记住太多状态
    - 人类无法长时间处理高强度复杂信息
    - 人类在情绪激动时无法做复杂决策
4. **组织约束**
    - 权限结构
    - 决策效率与路径
    - 信任机制
    - 责任边界

### 1.3.2 例子一：蛋白流程的物理墙

- 你不能无限大地开并行，因为：
    - IO 带宽有限
    - 单节点内存有限
    - 存储成本有限
- 你不能期望所有人都读懂复杂配置，因为：
    - 绝大部分使用者只想填表格、点按钮
    - 维护者有限

于是你必须承认：

> “这个流程的设计，必须在 **有限 IO + 有限记忆 + 有限维护者** 的条件下成立。”

**这就是物理约束，它比任何“理想架构”都更真实。**

### 1.3.3 例子二：乌克兰/非洲场景的物理墙

- 网络不稳定
- 设备可能被摧毁
- 人员可能突然撤离或失踪
- 信息泄露可能带来致命后果
- 上级组织可能并不可靠

这意味着：

> **任何系统设计，都必须允许“离线运行”、“部分损毁仍可工作”、
> “核心结构不依赖单点机构”、
> “隐私与安全优先于便利”。**

你不能设计一个“必须高带宽、必须中心服务器在线”的架构，然后说：“如果这些条件满足就很好用。”
 ——这不是设计，而是自欺。

### 1.3.4 例子三：亲密关系的物理墙

别笑，关系也有物理约束：

- 人不可能 24/7 在线回复你
- 人会疲劳、会崩溃、会误解
- 人无法完全理解对方的内在世界
- 情绪高涨时，理性渠道是部分关闭的

所以你不能设计一种“完美沟通结构”要求：

> “我们必须每次即时表达、即时回应、完全透明、完全共感。”

这违反了“心理物理学”，注定崩盘。

更合理的架构会承认：

- 冲突时，需要一个降温期
- 有些内容不适合在即时通讯中处理
- 需要“周期性回顾”的 runtime，而非“永远实时同步”的幻觉

### 1.3.5 一个简单的实践方法：写“约束表”

在任何系统设计前，你可以强制自己写一个 **Physical Constraints** 表：

- 本系统的硬限制是什么？
- 哪些约束是“绝对不可违反”的？
- 哪些约束一旦违反，就意味着系统设计不成立？
- 哪些约束其实只是“组织习惯”，可以挑战？

不做这一步，你设计的，到后来往往只是“情愿书”。

------

## **1.4 Zero-Based Optimal Architecture：如果从零开始，这个系统应该怎么长？**

前三步做完，你已经有了：

1. 正确的问题定义
2. 原子级别的系统分解
3. 明确的物理约束边界

现在才轮到一个最危险、但也最有创造力的问题：

> **“如果从零开始设计，在这些约束下，这个系统的最佳骨架是什么样？”**

这就是 **Zero-Based Optimal Architecture（零基最佳结构）**。

### 1.4.1 零基 ≠ 否定一切已有成果

“零基”不是说要否定所有历史积累，重新造轮子。
 而是说：

> **你暂时把所有历史路径依赖、惯性做法、既有工具都拿出视野之外，
> 只在“问题 + 原子 + 约束”的空间里寻找结构。**

举个例子。

蛋白流程现在的状态可能是：

- 目录结构是跟着某个软件的习惯走的
- 中间文件命名受旧脚本限制
- 调度方式被某个旧平台绑架
- 很多行为只是“我们一直这么做”

零基提问就是：

> “如果从今天开始，我只知道：
>
> - 需要从 RAW 到 diff
> - 一组原子（PSM、蛋白、样本、对比）
> - 机器资源是这样
> - 使用者认知是那样
>     那我会怎么画出一条最清晰、最易维护、最易替换工具的路径？”

你会发现，很多“一直这么做”的东西都不再必要。

### 1.4.2 一个现实中的“零基架构”例子：你的蛋白流程重构

你现在做的，实质上就是在做一轮 **零基架构实验**：

- 不再让流程的结构被单个软件（MaxQuant/DIA-NN）的输出目录驱动
- 而是由你定义的 **语义层节点 + 运行层 stage** 来驱动目录与中间状态
- toolbox 收拢工具调用，工具层从骨架中解耦
- 输出结构与中间状态分离
- IO 结构从“工具残留”变成“系统语义优先”

你用的是原有工具，但你已经在做“零基”。
 因为你在问的不是：

> “我们如何更高效地把旧流程跑快一点？”

而是：

> “如果蛋白流程作为一个系统，今天从零开始建，它的骨架应该是什么样？”

这个问题一旦问出口，后面的结构就不可能再完全退回旧状态。

### 1.4.3 战区/NGO/个人结构中的零基

- 战区：如果从零开始设计一个“求助 → 验证 → 调度 → 执行 → 反馈”的系统，在 **不稳定网络 + 高风险 + 部分失联** 的约束下，你还会从“建一个 Telegram 群”开始吗？
    大概率不会，你会从节点、冗余、可靠路径、最低必要信息开始。
- NGO：如果从零开始设计资源再分配系统，你还会直接照搬“公司 KPI + 科层制”吗？
    你可能会选择更松弛的网络结构、透明账本、隐私保护机制。
- 个人：如果从零开始设计自己的“存在性生活计划”，你还会从“提高效率、戒掉手机”开始吗？
    你可能会从“我在世界中的位置是什么”、“我真正愿意为之承受风险的结构是什么”开始。

**Zero-Based Optimal Architecture 的核心不是“造一个全新宇宙”，
 而是用“问题 + 原子 + 约束”来重新校准自己，而不是被旧系统牵着走。**

------

### 1.5 小结：四大基础操作如何接上 Skeleton 三层骨架

到这里，我们只做了四件事：

1. 找问题
2. 拆原子
3. 找墙
4. 画一张“如果从零开始”的结构草图

接下来才轮到本书的第二套结构登场：

- **语义层（Semantics）：系统究竟是什么？有哪些节点、contract？**
- **运行层（Runtime）：它如何运作？如何编排、记录、恢复？**
- **工具层（Tools）：最后用什么来实现这些结构？**

你可以把整个方法论的节奏记成一句话：

> **先用四个动作把世界从混乱切成“可设计”的形状，
> 再用三层骨架把“可设计”的东西变成“可实施、可迁移”的系统。**

------

## 第 2 章 · 语义层：系统真正“是什么”的那一层

> 在任何系统里，如果你连“它到底是什么”都没说清楚，
> 那后面的运行方式、工具选择，全都只是在堆功能。

语义层（Semantics Layer）回答一个看似简单、实际上经常被回避的问题：

> **这个系统，到底是什么？**

不是“用了什么语言写的”、
 不是“部署在哪个集群上”、
 也不是“挂在公司架构图的哪个部门”。

而是：

> **它由哪些“节点”构成，这些节点之间的关系是什么，它们各自承担什么意义？**

本章我们要做三件事：

1. 把“语义层是什么 / 不是什么”说清楚；
2. 给出一套可操作的构造方法；
3. 用几个具体场景（蛋白流程、战区志愿系统、亲密关系）落地。

------

### 2.1 为什么必须先把语义层说清楚？

回到第一章的四个基础动作：
 **问题定义 → 原子分解 → 物理约束 → 零基架构**，
 做完这些，你大概知道：

- 你真正在解决的是什么问题；
- 世界可以被拆成哪些原子；
- 哪些硬约束绕不过去；
- 在理想情况下，结构大概要长什么样。

**语义层，就是在这个基础上，把“结构”用人能理解的方式显式化。**

如果你跳过语义层，直接写代码 / 上容器 / 拉志愿者 / 建微信群，通常会出现几种后果：

- 你以为你在构建系统，实际上只是在堆工具；
- 新人加入时只能“背流程”，却说不出系统的骨架；
- 出问题的时候，没人知道“哪一层”出了错，只能靠玄学 debug；
- 当你想迁移到另一个国家、另一家公司、另一个场景时，发现一切都得重来。

语义层的意义很直接：

> **如果语义层清晰，你可以在不同 runtime 和工具上复刻同一个系统。
> 如果语义层混乱，你连“复制”都做不到，更别说迁移。**

------

### 2.2 语义层是什么，和什么不是

先用一个粗暴的对比表：

| 层级   | 问的是什么问题                     | 典型内容                                                     |
| ------ | ---------------------------------- | ------------------------------------------------------------ |
| 语义层 | 这个系统是什么？节点与关系是什么？ | Raw → Search → Quant → Diff；求助 → 调度 → 执行；需求 → 回应 |
| 运行层 | 它是如何被执行的？                 | 目录结构、队列、调度策略、失败恢复                           |
| 工具层 | 用什么具体东西来做？               | 软件、语言、框架、设备、通讯工具                             |

### **2.2.1 语义层不是：**

1. **不是“技术选型表”**

    - “我们用 Python + R + Docker + Kubernetes + DIA-NN + Slack”
        这些是工具层，不是语义。

2. **不是“组织架构图”**

    - “生信部 → 蛋白组学组 → 数据分析小组”
        这是管理结构，不是系统语义。很多组织用“部门结构”替代“系统结构”，然后整个系统跟着公司人事变化一起摇晃。

3. **不是“功能清单”**

    - “支持差异分析 / 支持富集 / 支持火山图”
        功能 ≠ 语义。
        功能是“它能干什么”；
        语义是“它在结构中是谁 / 扮演什么角色”。

4. **不是“流程图美化版”**
    很多流程图画得花里胡哨，箭头很多，但问一句：

    > “请用 5–10 个节点讲一下这个系统是什么？”
    > 讲不出来，那说明流程图只是装饰。

### **2.2.2 那语义层是什么？**

一句话：

> **语义层是一张“抽掉所有技术细节后仍然成立的系统结构图”。**

它有以下特征：

1. **节点数量有限（通常 5–12 个）**
    太多说明你还在画运行层甚至实现层；
    太少说明你在装哲学家。
2. **每个节点都有清晰的“角色句子”**
    例如：
    - “Raw QC：过滤掉明显错误的原始数据，避免垃圾进入后续阶段。”
    - “求助验证：确认这条消息确实来自现场，且内容可信。”
    - “冲突修复：在关系发生冲突后，试图恢复最低限度的合作结构。”
3. **节点之间的连线，表达的是“语义上的依赖关系”**
    例如：
    - 没有“Search”，就无所谓“Quant”；
    - 没有“求助验证”，就不应该有“资源调度”；
    - 没有“角色确认”，就谈不上“长期承诺”。
4. **语义层不依赖任何具体工具名称**
    不写 “MaxQuant”，写 “Search”；
    不写 “Telegram 群”，写 “信息汇聚节点”；
    不写 “微信消息”，写 “需求表达渠道”。

------

### 2.3 如何构造语义层：一套可执行的动作

你可以按下面四步来搭一套语义层结构。

#### Step 1：从问题定义和原子出发，列出“必要节点”

问自己：

> 在这个系统中，**必须经历的几种“意义上的阶段 / 角色”是什么？**

例如蛋白流程：

- 采集到的数据必须先被检查（Raw QC）；
- 然后把谱图和数据库匹配（Search）；
- 再把谱级信号汇总到蛋白（Quant/Protein）；
- 再做统计（Diff）；
- 最后形成可被人类消费的结果（Report）。

不管你用什么软件，这几个“阶段”在语义上都是必须存在的。

### **Step 2：给每个节点写一句“角色定义”**

强制自己用自然语言写一行：

- “本节点负责 X，是 Y 和 Z 之间的桥梁，输出供谁使用。”

如果你连一句完整的话都写不出，说明你其实没搞清楚这个节点在系统中的意义。

### **Step 3：画出依赖关系，而非执行顺序**

很多人画语义层图时，习惯按执行顺序排列：A → B → C → D。

更好的做法是：

- 标出“谁依赖谁的存在”；
- 而不是“谁先谁后”。

例子：

- “Diff” 依赖 “Protein 数据 + 分组信息”，而不是严格依赖 “Search”。
    你理论上可以不管 Search 是怎么来的，只要有 Protein table。
- 战区系统中，“资源调度”依赖 “已验证信息” 和 “可用行动单元”，
    而不是依赖“哪个电报群里发来的消息”。

### **Step 4：检查语义层是否“与工具无关”**

问自己一句：

> “如果我把目前使用的所有工具（MaxQuant、Telegram、Python、R）全部换掉，这张语义图是否仍然成立？”

如果答案是否定的，说明你画的是“实现层结构”，而不是语义层。

------

## **2.4 示例一：蛋白流程的语义层**

我们先把所有工具统统拿掉，只问：

> “从一堆原始信号，到一个可以被解释的生物学结论，这个系统在语义上必须经历哪些节点？”

一个可能的语义层：

1. **Raw Acquisition（数据采集）**
    - 系统从仪器那里接到的，是一堆原始信号。
    - 它们包含错误、噪声、异常运行。
2. **Raw QC（原始数据质控）**
    - 剔除明显错误的数据；
    - 标记仪器问题；
    - 为后续解释提供可信度基础。
3. **Spectrum-to-Sequence Mapping（谱级匹配 / Search）**
    - 把信号映射到肽段/蛋白假设；
    - 输出“不确定但有概率”的匹配结果。
4. **Quantification（定量）**
    - 把离散的匹配结果，整合成样本级的蛋白/肽丰度；
    - 引入批次效应、缺失值、噪声结构。
5. **Statistical Contrast（统计对比 / Diff）**
    - 在不同条件、组之间做差异；
    - 得到显著性、效应量、置信区间。
6. **Biological Framing（生物学框架化）**
    - 把统计结果映射回通路、功能、网络结构；
    - 提供给人类一个“可以被叙述”的结构化图景。
7. **Result Delivery（结果交付）**
    - 把复杂的结构压缩成报告、可视化、表格；
    - 让非技术人员也能接触到系统输出的“意义”。

你会发现，这张语义层完全不依赖于：

- 用的是 MaxQuant 还是 DIA-NN；
- 用的是 LFQ 还是 TMT；
- 用的是 R 还是 Python；
- 部署在公司自己的 HPC 还是云。

这就是语义层的力量：

> **只要这几个节点不变，你可以在任意技术栈上重构一个“蛋白流程”，
> 而不是重构一个“MaxQuant 工作流”。**

------

## **2.5 示例二：战区志愿系统的语义层**

现在把生信抽走，换成一个更极端的场景：
 乌克兰前线，或非洲偏远地区，一个志愿网络试图帮助真实的人。

如果你只从工具层出发，你会听到很多熟悉的句子：

- “建几个 Telegram 群，拉上所有人。”
- “搞一个 Google Sheet 记录需求和支援。”
- “再做一个小程序，让大家填表。”

这些都只是工具。
 如果你从语义层出发，你会得到另外一张图。

一个可能的语义层：

1. **Signal Intake（信号进入）**
    - 任何求助信息 / 风险信息，以某种形式进入系统。
2. **Validation（验证）**
    - 这条信息是否真实？
    - 是否来自可信源？
    - 是否重复？
3. **Prioritization（优先级评估）**
    - 危险程度、时间敏感度、可行性评估。
4. **Resource Mapping（资源映射）**
    - 哪些行动单元（人 / 车 / 物资）可以、应该响应？
    - 谁离得更近？谁更适合？
5. **Action Dispatch（行动下发）**
    - 把“谁应该做什么”的决定传递到执行单元；
    - 包含确认与接收。
6. **Execution & Feedback（执行与反馈）**
    - 行动执行；
    - 结果反馈回系统：成功 / 失败 / 部分完成。
7. **Archival & Learning（归档与学习）**
    - 记录这次事件的关键信息；
    - 用于未来决策改进。

你可以在任何国家、任何地缘环境下问：

- 这七个节点是否仍然有意义？
- 它们是否可以脱离电报、Excel、数据库单独成立？

如果答案是“是”，那你就抓住了语义层。

你之后再选择：

- 用 Mesh 网络路径传输；
- 用纸笔 + 实体板；
- 用 signal、matrix、whatsapp；
- 用 local-first 的 app；

这都只是工具与运行层的问题了。

------

## **2.6 示例三：亲密关系的语义层**

再换一个维度：
 我们把所有“鸡汤”和“心理学术语”抛开，只把关系视为一个系统。

你可以尝试画这样一张语义层图：

1. **Self Articulation（自我立场表达）**
    - “我是谁，我大致想要什么样的关系。”
    - 不是简历，而是某种存在的基本姿态。
2. **Role Negotiation（角色协商）**
    - 我们在这段关系中如何互相称呼、理解彼此的位置？
    - 是朋友、恋人、共事者、盟友、共谋者？
3. **Need Expression（需求表达）**
    - 对亲密、边界、陪伴、空间、节奏的具体需求。
4. **Contract / Rhythm（运行契约与节奏）**
    - 我们如何分配时间、见面频率、沟通频率？
    - 如何对突发事件进行调整？
5. **Conflict Handling（冲突处理）**
    - 误解、冲突出现时，有没有约定的处理方式？
    - 是冷处理、激烈争吵、暂停、寻求第三方？
6. **Repair & Growth（修复与共同成长）**
    - 冲突之后，关系如何恢复到某种新的、可能更稳的状态？
    - 是否能从事件中抽取结构性的调整，而不是单纯“熬过去”。
7. **Exit & Reconfiguration（退出与重构）**
    - 如果关系不再工作，如何结束？
    - 如何重构各自的生活结构，而不是互相拖死？

你会发现很多关系的问题，并不在“他晚回了半小时消息”，
 而是在：

- 从未有过“角色协商”；
- 没有“运行节奏协议”；
- 没有任何“冲突处理”机制。

换句话说：

> **工具层（微信、电话、礼物）非常丰富，
> 但语义层几乎是空的。**

这种系统在工程里叫：**“硬件非常花哨，协议一塌糊涂”。**

------

## **2.7 语义层上的常见错误**

### **错误 1：用工具层假扮语义层**

- “我们就是一个 Telegram 社区。”
- “我们就是一套基于 DIA-NN 的蛋白流程。”
- “我们就是一个长时间聊天的关系。”

这是最常见也最致命的错误：
 **把工具的名字，当成系统的名字。**

### **错误 2：语义层完全依赖组织结构**

- “这块是技术部的事，那块是市场部的事。”
- “这里归你管，那里归我管。”

组织结构可以服务语义层，
 但不能代替语义层。
 否则一调岗、一裁员，系统结构一并塌。

### **错误 3：语义层过度抽象，变成玄学**

- “我们的系统是为了让人类更加幸福与自由。”
- “我们的平台要重塑蛋白质组学研究范式。”

这些可以写在宣言里，但在语义层里没用。
 **语义层必须能落成 5–12 个有清晰输入输出的节点。**

### **错误 4：不允许语义层演化**

有的人一旦画了语义层，就当成“宇宙真理”，
 任何新的实践都必须被硬塞进旧图里。

更健康的做法是：

> **语义层是版本化的（v1, v2, v3）。
> 每一次大的经验冲击，都可以促使你更新一版语义骨架。**

你在蛋白流程里，现在大概是 Semantics v1；
 未来做完几轮项目、跨物种、跨平台，完全可以画出 v2/v3。

同样，关系的语义层也不是一成不变的。
 战区志愿系统随着战况、技术、参与者结构变化，语义图也会演化。

------

## **2.8 语义层的开放性：我们拒绝“完满结构”**

站在后康德视角，我们必须承认：

> **任何语义层，都是从有限实践中归纳出来的，不是从天上掉下来的本体。**

因此，本章的所有语义示例——蛋白、战区、关系——都只是一种 **当下条件下的“足够好”结构**：

- 它们有解释力；
- 它们可操作；
- 它们有迁移潜力；
- 但它们永远不可能是“最终版本”。

这意味着：

1. 语义层必须可以被实践修正；
2. 语义层的边界必须可讨论，而不是封闭；
3. 你在不同国家、不同组织，可以基于同一 Skeleton，再画出局部变体。

我们拒绝把 Design Skeleton 写成一个“黑格尔式的完满体系”。
 相反，我们强调：

> **语义层本身也是一个版本化对象，是可以被 fork、对比、演化的。**

------

## **2.9 小结：语义层是你真正能带到世界各地的东西**

到目前为止，我们做的事情可以压缩成一句话：

> **语义层就是：
> 当所有工具、组织、人事、具体实现都抽掉以后，
> 那张你仍然能画出来的“这个系统是什么”的图。**

你可以把它带到任何地方：

- 到另一家公司重建一个蛋白流程；
- 到战区搭一个最小可用的支援网络；
- 到非洲做一个粮食与医疗分配系统；
- 在自己的生活里搭一个“存在性生活计划”。

在接下来的章节，我们会基于这套语义层：

- 在第 3 章讨论 **运行层（Runtime）：系统如何运作、记录、恢复、扩展**；
- 在第 4 章讨论 **工具层（Tools）：如何选择、封装、替换、避免被反客为主**。

语义层是第一根骨头。
 有了它，后面的运行层与工具层，才有东西可以“为之服务”，而不是相互拖死。

------

如果你觉得这一章整体方向和风格对路，我们可以继续写 **第 3 章 · 运行层：系统如何“活起来”**，
 把目录结构、队列、错误恢复、调度策略、战区/关系中的“运行节奏”等全部放进去。



好，那我直接写成正式白皮书体的第三章 v1。

------

# 第 3 章 · 运行层：系统如何“活起来”

> 语义层回答的是：**“这是什么系统？”**
> 运行层回答的是：**“它每天实际上是怎么活的？”**

很多系统在纸面上看起来完美：
 节点划分清晰，关系合理，语义结构漂亮。
 一旦落地，就开始出现这些症状：

- 跑几次就崩；
- 错一次就得重头来；
- 一换人就没人敢动；
- 一旦环境条件变化（网络、电力、人手），整个系统直接瘫痪。

问题不在语义层，而在 **运行层（Runtime Layer）**。

本章要解决的核心问题是：

> 在给定的语义结构之上，
> **如何设计一套稳得住、跑得动、扛得住失败和变化的“生命结构”？**

------

## 3.1 运行层到底是什么？

我们先用三个简单的问题确定运行层的边界：

1. **任务从哪里来，怎么被排队，谁来执行？**
2. **系统状态如何被记录？失败时能回到哪里？**
3. **资源（时间、人力、算力、带宽）如何被安排？**

如果说语义层是“身体结构图”，
 运行层就是：

- 血液怎么流；
- 神经怎么传；
- 受伤时怎样止血、结痂；
- 力量怎样分配给不同部位。

用一句更工程的说法：

> **运行层是“系统如何在现实约束下持续运行”的设计。**

它包含但不限于：

- 目录结构 / 状态布局
- 队列与调度
- 错误处理、重试与恢复
- 日志与监控
- 周期性任务 / 生命周期管理
- 并发与资源限制（在物理约束内）

注意：
 **运行层不关心用的是哪种具体工具。**
 那是工具层的事。

------

## 3.2 运行层不是 / 是什么

### 3.2.1 运行层不是

1. **不是“语义层的换皮版本”**
    运行层不是再画一遍 Raw → Search → Quant → Diff。
    它关心的是：
    - Raw 放在哪个目录？
    - Search 任务如何排队？
    - Diff 出错时怎样不影响上游结果？
2. **不是“工具层的堆砌”**
    写一堆 shell 脚本、堆一堆 crontab、拉几个容器，并不自动构成运行层。
    它们如果没有统一的结构与约定，只是“工具噪声”。
3. **不是“项目管理甘特图”**
    项目进度表关注“哪天开会”“谁负责哪块”，
    运行层关注的是：**系统每天如何自动、重复地运转，出了问题如何自洽。**

### 3.2.2 运行层是

你可以把运行层理解成下面几个问题的“统一回答”：

- **状态在哪里？**
    目录怎么布置？数据库怎么切分？
    哪些是中间态，哪些是最终态？
- **时间怎么流？**
    有无队列？是否允许并发？
    是否有周期任务或异步机制？
- **出错时怎么办？**
    重试几次？从哪里重启？
    是否有“最小损失重启点”？
- **资源如何被限制和分配？**
    一个节点最多跑多少任务？
    用户 / 项目 / 样本之间如何公平？
- **运行轨迹如何被记录？**
    日志存在哪里？
    有无统一格式？
    事后能否复盘？

只要能让这几个问题在同一个结构下被回答，
 你的系统就算有了一套成型的运行层。

------

## 3.3 从语义层到运行层：必须跨过的三道坎

把第 2 章的语义层当成“骨骼图”，
 运行层就是把骨骼变成有血有肉、会走路的身体。

这个过程需要跨过三道坎：

1. **从“概念节点”到“具体状态与文件布局”**
2. **从“逻辑顺序”到“实际调度与并发策略”**
3. **从“理想流程”到“失败场景下仍然可继续”的结构**

我们用三个场景来说明。

------

## 3.4 示例一：蛋白流程的运行层设计

### 3.4.1 简化后的运行问题

假设语义层已经确定为：

> Raw Acquisition → Raw QC → Search → Quant → Diff → Report

现在你要回答的运行问题包括：

- 每个阶段的输入、输出在哪里？
- 中间文件是否保留？保留多久？
- 如何避免一个失败的样本拖垮整个项目？
- 如何在多样本、多条件的情况下并行？
- 出错后如何定位、重跑？

这就是典型的运行层问题。

### 3.4.2 目录骨架：in / tmp / out / logs

你已经在实务中自然走到了这一点：

```text
project_root/
  config/
  raw/
  work/
    stage_raw_qc/
      in/
      tmp/
      out/
      logs/
    stage_search/
      in/
      tmp/
      out/
      logs/
    stage_quant/
      in/
      tmp/
      out/
      logs/
    stage_diff/
      in/
      tmp/
      out/
      logs/
  result/
    tables/
    plots/
    report/
    logs/
```

这其实就是一个典型的运行层决策：

- **所有中间状态放在 work/**
- 每个 stage 有固定的 in/tmp/out/logs 结构
- result/ 只留对外可见的最终成果
- config/ 分离出配置与语义信息

这使得：

- 任何人只看目录，就能知道
    “系统现在大概运行到了哪里”；
- 任何 stage 出错，都可以只清理自己的 tmp/out/logs，
    而不污染上游。

### 3.4.3 重启点与失败策略

一个好的运行层一定会设计：

- **最小重启单元**：
    例如以样本为单位，以 stage 为单位；
- **失败后的策略**：
    - 某个样本失败，是整体失败，还是跳过？
    - Diff 时部分样本缺失如何处理？

你在实际工作中已经感受到：
 **“错一次就重跑全流程” 是典型运行层灾难，而不是技术问题。**

运行层的任务是：

> 把“可恢复性”做成结构，而不是指望“不要出错”。

### 3.4.4 日志与监控：让运行“可见”

运行层的另一个核心问题是：

> 系统是否能告诉你“我现在在干什么”？

统一的日志结构（按 stage、按样本）、
 清晰的开始/结束/错误记录，
 都是运行层的一部分。

当你在凌晨想要知道“为什么 Diff 没出来”，
 你应该：

- 看一眼 logs/
- 知道卡在哪个 stage / 哪个样本 / 哪个命令上

而不是：

- SSH 上去翻各种历史命令、手动 grep。

这不是“多一点工程细心”的问题，
 这是运行层有没有被设计出来的问题。

------

## 3.5 示例二：战区志愿系统的运行层

把场景从蛋白换到战区。

语义层已经确定为：

> Signal Intake → Validation → Prioritization → Resource Mapping → Dispatch → Execution → Feedback → Archival

现在问运行层的问题：

- 求助信息具体如何进入系统？谁可以录入？
- 信息是否进入一个队列？如何排序？
- 谁有权限做验证？如何避免单点过载？
- 行动任务如何分配？是否允许多个行动单元抢单？
- 执行完如何确认？失败了怎么处理？
- 在网络断裂或部分节点离线时，系统是否还能运作？

### 3.5.1 “纸 + 人 + 简单工具”也可以有运行层

一个极端例子：
 即使你没有任何服务器，只能用纸、对讲机、偶尔能连的手机，
 你仍然可以设计运行层，例如：

- 所有新求助都写在一块白板左侧（Signal）
- 经验证的信息移到中间区（Validated）
- 已派出行动的标记为 In-progress
- 完成的标为 Done，失败的标为 Failed
- 每小时由一个人负责“扫描白板”，把状态同步给不同小组

你会发现，这跟现代看板、任务队列、消息队列的结构，是一模一样的。

区别只在于：

- 工具层是白板和人
- 但运行层的结构，即“状态迁移 + 节奏 + 责任划分”，本质相同

### 3.5.2 失败不是例外，而是常态

战区最残酷的一点是：

> **失败不是异常，而是常态。**

通信中断、行动失败、人员伤亡、信息延迟，
 在这种环境下，如果你还试图用“理想流程图”来指导系统，
 那只是在自我安慰。

一个现实的运行层会假定：

- 信息会乱；
- 节点会断；
- 任务会失败；
- 人会离开；
- 没有人“永远在线”。

于是运行层的设计会倾向于：

- 冗余路径（两个以上的传输渠道）；
- 简化状态机（减少状态数量，避免复杂分支）；
- 允许部分信息脱机缓存（local-first）；
- 对关键节点设置备份角色。

换句话说：

> 在战区，运行层被“物理约束”硬性塑形，
> 你能否接受这一点，会直接决定系统是“活的”还是“假想的”。

------

## 3.6 示例三：关系中的运行层——节奏、规则与修复机制

看起来最“不工程”的地方，往往最需要结构。

我们可以尝试这样看待亲密关系的运行层：

- **语义层**：
    自我立场 → 角色协商 → 需求表达 → 契约与节奏 → 冲突处理 → 修复与成长 → 退出与重构
- **运行层**要回答的问题是：
    - 我们多久沟通一次？
    - 遇到压力、崩溃期，系统如何“降档运行”？
    - 冲突时，是否允许暂停？由谁先开口？
    - 重要议题如何进入“正式讨论通道”，而不是永远在碎片化对话中漂浮？

### 3.6.1 缺失运行层的典型结果

很多关系的问题，表面看是：

- “你不够在乎我”
- “你太黏人了”
- “你总是消失”

但往往深一点，是：

> **关系作为一个系统，只有“语义层想象”（我们是什么）和“工具层操作”（发消息、见面、礼物），
> 几乎没有运行层设计。**

比如：

- 没有明确约定“高压力时期可以怎样暂时撤退”；
- 没有“冲突正式讨论”的固定机制；
- 没有“周期性 review”的惯例；
- 没有“当我们吵到无法沟通时，找谁第三方介入”的约定。

于是所有问题都被压到“即时对话”和“情绪爆发”里，
 系统自然难以长久运作。

### 3.6.2 关系的运行层可以很朴素

你不需要把关系搞成企业管理那套，但可以非常朴素、非常具体：

- 每周一次“系统级对话”：不解决琐事，只讨论结构（节奏、角色、边界）。
- 约定一个“暂停词”：当某一方说出这个词，表示“我要暂时退出当前争吵，以较低状态运行，但不等于关系终止”。
- 设置“强制冷却期”：冲突后 24 小时内不做任何重大决定（分手、搬家等）。
- 每季度“版本回顾”：我们现在的语义层是否变了？运行节奏是否适合当前状态？

这些都是运行层上的朴素设计——
 它们不需要 App，不需要算法，但极大改变系统的可持续性。

------

## 3.7 运行层设计中的常见错误

### 错误 1：运行层被“工具默认值”绑架

- 用哪个框架，就跟着它的目录结构走；
- 用哪个 IM 软件，就让关系节奏完全被“已读 / 未读”支配；
- 用哪个云平台，就让整个系统的重启点被对方底层设计决定。

这是最常见的“反客为主”：
 **工具层在偷占运行层的位置。**

### 错误 2：假设“一切按理想顺序执行”

很多流程图只有一条线，没有失败分支，也没有“部分完成”的状态。

运行层如果不容纳失败，就等于没设计：

- 不考虑重试上限；
- 不考虑“部分成功”的记载；
- 不考虑资源不足时的降级策略；
- 不考虑“下游可在缺少部分上游数据时以弱状态运行”。

在现实世界里，这等于拒绝和现实打交道。

### 错误 3：没有统一状态模型

- 有的东西写在文件名里；
- 有的东西写在 Excel 里；
- 有的东西在日志里；
- 有的东西只存在某个员工脑子里。

结果就是：

> 出一次问题，所有人开始打电话 / 发消息 / 口口相传，
> 系统退化成人肉协作。

运行层如果无法统一关键状态（哪一步做完了，哪一步失败了），
 就难以做任何自动恢复或可靠调度。

### 错误 4：运行层被视为“实现细节”

很多人喜欢谈：

- 宏大目标（语义层理想）
- 炫酷技术（工具层炫技）

但懒得认真设计：

- 日志格式
- 目录布局
- 错误策略
- 恢复点
- 并发限制

这些都被视为“执行细节”，
 然后系统就以“细节堆积的方式”崩溃掉。

------

## 3.8 开放性：运行层也是版本化的

就像语义层不是本体论真理，
 运行层也不是一锤定音。

在现实世界中，运行层尤其需要：

- 随着规模、环境变化而演化；
- 允许局部试验新的结构（比如新的重启策略、新的队列）；
- 允许根据反馈调整资源分配和节奏。

你在蛋白流程中可以有：

- Runtime v1：单机 + 简单目录 + 手动重启；
- Runtime v2：集群 + 任务队列 + 半自动重启；
- Runtime v3：分布式调度 + 容器 + 状态服务。

同样，战区志愿系统：

- 早期可能只是一块白板 + 一部手机；
- 中期可能是一个简单的 local-first 应用；
- 后期可能接入更完整的消息队列与安全层。

关系也是：

- 初期运行层非常松散；
- 逐渐形成稳定节奏与冲突处理惯例；
- 在环境变化（搬家、换工作、战争）时被迫升级版本。

**关键不是“找到完美运行层”，
 而是承认：运行层是一个你可以持续调整和重构的结构，而不是自然发生的东西。**

------

## 3.9 小结：运行层让系统有“生命感”，而不是“一次性项目感”

这一章我们做的事情可以压缩为一句话：

> **语义层让系统“有骨头”，
> 运行层让系统“活着”。**

有了语义层，你知道系统是什么；
 有了运行层，系统才能：

- 在约束中持续运行；
- 在失败中保持可恢复；
- 在环境变化时依然有某种稳定；
- 在迁移和扩展时保留原有结构。

在接下来的第 4 章，我们会继续往下走：

> **工具层（Tools）：如何选择、封装、替换工具，
> 让工具服务于骨架，而不是让骨架为工具打工。**

如果你觉得目前的节奏和深度合适，我们下一个就写第 4 章。

好，咱们把最后这一块骨头也钉上去。

------

# 第 4 章 · 工具层：所有工具都会死，但系统不该跟着陪葬

> 语义层回答“这是什么系统”，
> 运行层回答“它每天怎么活”，
> 工具层只回答一个问题：
> **“在当下这组条件下，我们用什么来把它做出来？”**

这一章讲的不是“用 R 还是 Python”“用哪个框架更炫”，
 而是更冷冰冰的一件事：

> **如何承认所有工具都会死，同时又让系统活得比工具久。**

------

## 4.1 工具层到底是什么？

我们先用一句非常粗暴的话定义：

> **工具层 = 在当前历史阶段、当前资源条件下，
> 我们选择的一组“可被抛弃的实现手段”。**

它包括但不限于：

- 编程语言：R / Python / Go / Rust / …
- 软件工具：MaxQuant、DIA-NN、PLINK、bcftools、emapper
- 运行时 & 容器：conda/micromamba、Docker、K8s、Slurm
- 基础设施：某家云、某个 HPC 集群、某个存储系统
- 通信工具：微信、Telegram、Signal、邮件、短波电台
- 仪式与媒介（在关系和社会系统中）：礼物、节日、即时通讯、共同活动

这些东西有一个共同特点：

> **它们不是系统本身，只是当下实现系统的手段。**

------

## 4.2 工具层 *不是* 什么

### 4.2.1 不是身份认同

- “我们是一个 Python 团队。”
- “我们是 Telegram 社群。”
- “我们是用 DIA-NN 的生信公司。”

把工具变成自我认同，是最危险的事之一——
 一旦工具失效，你连“我是谁”都跟着崩。

### 4.2.2 不是语义

- “我们就是一个 Slack 社区。”
- “我们的系统就是 WDL 工作流。”
- “我们的关系就是无话不谈的微信聊天。”

这些句子把工具当成系统本身，
 是上一章说过的 “工具假扮语义层”。

### 4.2.3 不是运行层

- “我们用 Airflow，所以调度有保障。”
- “我们用 Kubernetes，所以弹性伸缩有保障。”

这些都只是**运行层的可能实现**，
 不是运行层的结构本身（队列、重启点、状态模型）。

------

## 4.3 工具层真正是什么

你可以把工具层当成三件事的集合：

1. **适配器（Adapter）：**
    把语义层 & 运行层期待的“接口/行为”，翻译成具体工具的调用。
2. **封装的依赖（Dependencies）：**
    当前系统运行需要的具体软件、库、协议。
3. **可替换的外骨骼（Replaceable Shell）：**
    当环境改变时，可以整体替换的一层，而不伤到内核结构。

所以，工具层真正的设计问题不是：

> “用什么语言、什么框架最好？”

而是：

> **“在不污染语义层和运行层的前提下，
> 我们如何用最小代价，控制、封装、替换这些工具？”**

------

## 4.4 所有工具都会死：接受这一点，很多设计自然会变

这一点要刻骨铭心：

- 语言会退潮（Perl、Fortran 的故事已经演过一轮）；
- 软件会停更；
- 容器格式会换；
- 云厂商会改价甚至关服务；
- 通讯工具会被封锁、墙掉、禁用；
- 法律环境会让一些原本合法的工具变成负资产。

**所以一切以“工具不变”为前提的架构，都是注定要付出巨大代价的。**

你现在感到“工具选型”很痛，其实是件好事——
 说明你已经在意识到工具层的脆弱性，而不是对它抱神话期待。

------

## 4.5 工具层设计的五个原则

这里给一套你可以长期记住的原则，它们**不和具体技术绑定**：

### 原则 1：**工具最后绑定，语义最先确定**

> **语义 & 运行结构先定型，
> 工具尽量晚选、尽量可换。**

顺序不能反过来。

坏的顺序是：

- 先选 “我们要用某某技术栈”；
- 再强行往里面塞问题；
- 最后发现问题与技术栈结构不 match。

好的顺序是：

1. 定义语义骨架（这一系统是什么？有哪些节点？）；
2. 设计运行层（状态、队列、目录、重启点）；
3. 最后问：
    - “在当前资源限制下，哪个工具最便宜、最稳、最易被替换？”

### 原则 2：**总有一层“适配层”**

不要让系统各处都是直接调用某个大工具（DIA-NN、emapper、PLINK）的杂乱脚本。

更健康的结构是：

```text
[语义层 / 运行层]
        ↓ 只接触 “我们的接口” (e.g. run_search(), run_emapper())
   [适配层（toolbox_xxx）]
        ↓ 调用
   [具体工具命令 / API / 容器]
```

这就像在墙上安装插座，而不是把电线直接露在外面：

- 工具更换时，主要动适配层；
- 上层逻辑基本不动。

### 原则 3：**环境封装，而不是环境散落**

包管理、虚拟环境、容器，本质都是在说一件事：

> **工具的依赖和版本应该被显式、可复制地封装起来，
> 而不是散落在系统的各个角落。**

- micromamba/conda 环境、Python venv、R renv
- Docker 镜像
- Nix 等声明式环境

目的都不是“显得高级”，是为了：

- 别人在别的机器上也能跑；
- 你半年后还能复现；
- 换机器/云平台时不至于从地狱爬一遍。

### 原则 4：**工具层也要有“生前约定”**

工具层要有自己的 contract：

- 某个镜像负责什么？
- 环境里严格包含哪些东西，不包含哪些？
- 工具的输入输出格式是否统一、稳定？

别让一个容器既做搜索又画图又打报告，那是运行层和工具层粘成一团。

### 原则 5：**工具选型是“战术决策”，不是“形而上战争”**

你可以有偏好，但不能有信仰。

- 喜欢 R 也好，喜欢 Python 也好，都没问题；
- 真正的问题是：
    - 在这个场景下，这个工具是不是最小可行解？
    - 替换成本是否可控？
    - 团队/环境是否实际能维护？

**工具不是价值观，是战术。**

------

## 4.6 示例一：蛋白流程里的工具层重构

我们用一个你非常熟的场景来对照“好 / 坏”两种工具层姿态。

### 4.6.1 坏的工具层姿态（现实中常见）

- 所有脚本直接在 shell 里 `MaxQuantCmd.exe`、`DIA-NN.exe`；
- 软件装在某个服务器的奇怪路径下，只有一个老员工知道；
- 不同项目用的 MaxQuant 版本不一致；
- R 包、Python 包散装在系统级环境；
- 举头三尺都是 `module load ...` + 一堆手工 export。

结果：

- 换一台机器，所有脚本全废；
- 工具升级时，不敢动老项目；
- debug 时无法区分“代码问题”“环境问题”“软件 bug”。

### 4.6.2 健康的工具层姿态

你现在慢慢在走的，是另一条路：

1. **语义层**：流程节点固定为 Raw QC / Search / Quant / Diff / Report。
2. **运行层**：每个 stage 有自己的 `in/tmp/out/logs`、统一元数据结构。
3. **工具层**：
    - 用 Docker / micromamba + renv 锁住特定版本；
    - 把具体工具调用封装进 `toolbox_py/toolbox_r` 的函数里，比如 `run_diann_search()`, `run_maxquant_search()`；
    - pipeline 中不直接写 `diann --this --that`，而是调用你的 `run_search(stage_config)`；
    - 工具层自己有 changelog 和版本号（例如 `toolbox-py v0.3`）。

结果是：

- 将来想从 DIA-NN 换到别的 search 引擎，只要在工具层多实现一个适配器函数；
- 语义层、运行层几乎不动；
- 某天你人在乌克兰，拿到一个完全不同的集群，也能把这套骨架迁移过去。

工具死亡，系统不死；
 这是你真正要争取的。

------

## 4.7 示例二：战区 / NGO 系统中的工具层——从 Telegram 到一支铅笔

战区志愿系统的语义层我们已经有了：
 Signal Intake → Validation → Prioritization → Resource Mapping → Dispatch → Execution → Feedback → Archival

运行层也有：白板 / 看板 / 轮班 / 冗余。

那工具层长什么样？

### 4.7.1 工具层可能的选择

- 通信：Telegram、Signal、WhatsApp、短信、卫星电话、短波电台
- 记录：Google Sheet、本地数据库、纸笔、墙上的白板
- 定位：GPS、离线地图、打印地图 + 手工标记
- 调度：简单的 Web 界面、CLI 工具、物理看板

### 4.7.2 如果把工具当成系统，会发生什么？

比如说：

> “我们就是一个 Telegram 群/频道。”

那一旦：

- Telegram 被封锁；
- 某地区完全断网；
- 账户被整批封禁；

**整个“系统”就跟着消失。**

这说明你根本没设计语义层/运行层，只有一堆工具使用习惯。

### 4.7.3 把工具当成实现，而不是当成存在

更健康的姿态是：

- 语义层：我们是一个“从信号 → 行动”的网络；
- 运行层：即使用纸和人，系统仍然可以部分运行；
- 工具层：
    - 在宽带良好的地区，首选 Telegram + Web；
    - 在封锁地区，退回到 SMS + 短波 + 实体看板；
    - 在完全断网区域，用纸+信使+约定时间节点。

你真正关心的不是：

> “我们是用什么 App 的组织。”

而是：

> **“在这些约束下，今天用哪组工具最能支撑语义和运行结构？”**

有一天你人不在原国家、原公司、原组织，
 你照样可以把同一套系统重建起来，只不过工具是新的。

------

## 4.8 示例三：亲密关系中的工具层——仪式可以变，结构不能丢

回到看似“最不技术”的场景。

在关系系统里，工具层包括：

- 用什么渠道沟通（微信、电话、邮件、见面）
- 以什么频率发送消息
- 是否有共同活动（看电影、旅行、一起工作）
- 仪式性行为：礼物、纪念日、照片、社交媒体互动

很多人会下意识地把这些当成关系本身：

- “他很久没给我发早安了，我们是不是不爱了？”
- “以前天天聊天，现在没话说，是不是结构崩了？”
- “她不再发朋友圈，是不是对我冷淡？”

如果没有语义层和运行层的自觉，很容易落到：

> **把工具 / 仪式失败，当成关系失败。**

健康一点的设计是：

- 语义层：我们是什么关系？各自的立场是什么？
- 运行层：我们的基本节奏是什么？遇到高压期如何降档？冲突如何修复？
- 工具层：
    - 在某些时期，微信非常高频；
    - 在某些时期，可能主要靠见面、偶尔通话；
    - 仪式可以变形：从“每天汇报生活”变成“每周一次深谈”；
    - 某个渠道（比如微信）因为职业、环境变化被迫减少，系统应该可以转到别的形式，而不是直接解体。

你不需要把这些写成合同，但你至少需要在心里有一个区分：

> “聊天频率下降”
> ≠ 语义必然崩溃，
> 但
> “没有任何运行上的修复 / review 机制”
> 才是真正的结构风险。

这也是一种工具层的松紧度设计：
 **工具可以变，但不能让工具完全决定系统生死。**

------

## 4.9 工具层常见的几种灾难性误用

### 灾难 1：工具即信仰

- “我们要 All in 某某技术栈 / 某某云 / 某某生态。”
- “学这个语言一辈子都有饭吃。”

这在短期可以形成团队认同，
 长期往往会变成技术锁死和思维惰性。

### 灾难 2：工具驱动架构

- “我们选了 K8s，所以必须用它的方式来设计所有服务。”
- “我们选了 WDL，所以所有流程都围绕 WDL 的语义来做。”

工具可以反向启发架构，
 但如果架构完全从工具的约束出发，
 你做的是“工具的附属系统”，而不是“独立系统”。

### 灾难 3：工具堆叠取代结构思考

- “我们加一个消息队列，再加个缓存，再加个监控，再加个 service mesh……”
- 但没人能清楚地解释：**系统的语义层到底是什么？运行层的状态机长什么样？**

这是当代工程界的一大通病：
 **用复杂工具抵消结构贫乏感。**

### 灾难 4：对“新工具”的魔法幻想

- 以为换成 Rust / Go / AI / 某云，就能自动解决旧系统结构问题；
- 实际上只是在旧骨架上贴新皮，然后问题原封不动。

你现在对这点很警觉，这是好事。
 因为你日后接触更大的系统时，“换工具解决一切”的诱惑只会更强。

------

## 4.10 开放性：工具层应当始终处于“可被砍掉”的状态

站在 Design Skeleton 的角度：

- 语义层是你要认真维护、慢慢迭代的“内核”；
- 运行层是你要反复调优、根据实际经验升级的“动脉系统”；
- 工具层则应该始终被看作：**必要但可牺牲、可替换的“皮肤”。**

这意味着：

1. 工具选型不应该成为价值审判的全部依据；
2. 工具寿命不应该超过它的历史条件；
3. 工具变化时，你应当有一套“迁移路径”，而不是集体崩溃；
4. 真正值得你带到世界各地的是：
    - 如何区分语义 / 运行 / 工具；
    - 如何围绕问题和约束来选工具；
    - 如何组织“适配层”和“环境封装”。

------

## 4.11 小结：工具是刀，不是信仰

这一章可以浓缩成一句话：

> **工具层是：
> 在当前时代条件下，为语义层和运行层服务的一套可抛弃实现。
>
> 它必须被封装、被约束、被随时替换，
> 而不应该被奉为身份认同或宇宙真理。**

你真正要带走的，不是：

- “R 比 Python 好”，
- “WDL 比 Nextflow 好”，
- “Telegram 比微信好”，

而是：

> **面对任意环境和限制，你都有能力：
> 先看清问题 → 拆出原子 → 找到约束 → 画出零基架构，
> 再在其上定义语义层和运行层，
> 最后用一组当下可行的工具把它实现出来。
>
> 工具死了，系统骨架还在；
> 系统迁移了，你这个人也不会被掏空。**

------

到这里，Skeleton 的三根骨头（语义 / 运行 / 工具）已经搭起来了。

接下来如果继续写，我们可以进入：

- 一整章“完整示例”（比如蛋白流程 / 战区志愿系统 / 个人存在性生活计划三选一或多选）
- 或者写一章“如何把 Skeleton 用于你的人生路线与未来行动（非洲 / 乌克兰 / 分布式结构）”。

你更想先写哪一块？
 完整工程示例，还是“如何拿 Skeleton 来重写你自己的人生架构”？

好，那我们来写一章“能落地、能复用、能带出公司”的工程示例。

我直接按白皮书正式体来写第 **5 章**。

------

# 第 5 章 · 完整工程示例：从“工具驱动的蛋白流程”到“可迁移的系统骨架”

> 这一章，我们不再抽象谈“骨架”，
> 而是从一个具体场景出发，把 Skeleton 全程走一遍——
> 从问题定义，到原子分解，到语义/运行/工具层的完整重构。

场景很简单也很典型：

> 某公司已有一条“能跑但脆弱”的蛋白质组学分析流程。
> 它串联了多个工具（MaxQuant / DIA-NN / R / Excel / 自制脚本），
> 能产生结果，但结构混乱、复现困难、难以迁移、难以维护。

本章不做“产品宣传”，只做一件事：

> **演示如何用 Design Skeleton，把这条流程从“堆工具”变成“系统骨架”。**

------

## 5.1 起点：一个“典型但危险”的原始状态

先描述一个典型现状，你应该会很熟悉：

### 5.1.1 表面上看，它“能跑”

- 有一套既定的“实验后分析”流程：
    实验 → 上机 → MaxQuant/DIA-NN → 差异分析脚本 → 富集分析脚本 → 出图 → 报告。
- 不同项目之间，通过复制旧项目目录、改一点脚本、改一点参数完成。
- 某些关键步骤由“经验最丰富”的分析师手动执行，别人不太敢动。

表面看起来，一切都“有经验可循”。

### 5.1.2 实际上，它到处都在咬人

具体症状包括但不限于：

- 目录结构随项目变化，没有统一规范；
- 临时脚本、一次性文件和正式结果混在一起；
- 有人直接在结果目录里手动改表格（为了“省事”）；
- 差异分析、富集分析在 R 包、Python 脚本、Excel 操作之间跳来跳去；
- 出问题时，很难知道是“数据问题 / 工具 bug / 环境问题 / 人为误操作”；
- 新人很难理解整个流程，只能照着老项目复制粘贴。

一句话：

> **这是一个“能跑”的工具集合，而不是一个“可迁移的分析系统”。**

------

## 5.2 Stage 0：用四大基础操作，把混乱切成“可设计”的形状

我们先完整套一遍第 1 章的四个动作：
 Problem Definition / Atomic Decomposition / Physical Constraints / Zero-Based Architecture。

### 5.2.1 Problem Definition：真正的问题是什么？

表面抱怨通常是：

- “流程太慢”；
- “太乱、太难改”；
- “每个项目都像重新打一仗”。

如果只停在这里，接下来通常就是：

- 换更快的工具；
- 再写一层“总控脚本”；
- 再贴一层前端 UI；

然后问题几年后重演。

真正的问题可以被压缩成一句话：

> **这条流程没有清晰的语义层，没有统一的运行层，
> 只有一个被工具和历史习惯驱动的“工具拼盘”。**

更具体一点：

- 项目结构由工具输出目录反向决定，而不是由语义结构决定；
- 中间状态没有统一规范，导致失败很难局部重启；
- 工具版本和环境散落在不同机器和用户的 home 目录；
- 对“什么是这个系统”的回答，只能是：“就是这堆脚本，照着上次项目跑”。

所以真正的问题定义是：

> **我们缺少一个“独立于具体工具的蛋白分析系统骨架”，
> 它需要能承载不同工具、不同环境、不同团队成员，
> 而不每次都从零搭一堆杂乱脚本。**

### 5.2.2 Atomic Decomposition：原子是什么？

从这条流程中拆出“原子单元”，而不是“工具模块”：

- 原始数据原子：一个 RAW 文件；
- QC 原子：一条“样本 QC 记录”；
- 谱级原子：一条 PSM / 一条 MS/MS 记录；
- 蛋白原子：一条蛋白定量记录（Sample × Protein）；
- 对比原子：一条“Contrast 定义”（GroupA vs GroupB）；
- 统计原子：一条“基于某种模型产生的检验结果”（Protein × Contrast）；
- 富集原子：一条“Pathway/GO Term 的富集结果”；
- 可视化原子：一张图中的一个点 / 一个柱 / 一个 tile；
- 报告原子：一块具体的结果区块（某个表格页、某个图）。

拆到这个粒度后，我们不再问：

> “MaxQuant 能干什么？DIA-NN 能干什么？”

而是问：

> “这些原子如何从一个阶段，流动到另一个阶段？”

### 5.2.3 Physical Constraints：具体的“硬墙”是什么？

现实条件往往是这样的：

- HPC 集群内存有限，I/O 带宽有限；
- 单个项目的总数据量可以很大，但不能占用集群无限资源；
- 分析团队有多人，经验不一致；
- 不同项目、不同批次可能用不同的仪器、不同的 Search 引擎；
- 项目截止时间紧张，不能每次都做为期一年的“大重构”。

这些约束意味着：

- 不能靠“全量重跑 + 人肉维护”来保证稳定；
- 必须有局部重启、渐进优化的能力；
- 必须能支持混合工具（不同项目用不同 search 引擎），但结果抽象一致；
- 必须能容纳不同经验水平的人，在骨架之上进行“有限度自由发挥”。

### 5.2.4 Zero-Based Optimal Architecture：如果从零开始，这条流程应该长成什么样？

在只考虑“问题 + 原子 + 约束”的前提下，你会得到一个直观答案：

> **我们需要一个三层结构：**
>
> - 语义层：Raw → RawQC → Search → Quant → Diff → Enrichment → Report；
> - 运行层：每个 stage 有统一的 in/tmp/out/logs 和元数据；
> - 工具层：每个 stage 的具体实现（MaxQuant / DIA-NN / 自研脚本）被封装在 toolbox 中，可替换。

只有这样，未来你才能：

- 换 Search 引擎，而不是重写整个流程；
- 换容器平台，而不是重搭所有环境；
- 换团队成员，而不是从头培训“这堆神秘脚本”。

------

## 5.3 Stage 1：语义层——重画“这条流程究竟是什么”

基于第 2 章的方法，我们可以给出一个清晰的语义层图。

### 5.3.1 语义节点清单（不含任何工具名字）

用 7 个节点描述：

1. **Raw Acquisition**
    - 从仪器拿到原始数据文件；
    - 关心的是“它真的是这次实验的输出”。
2. **Raw QC**
    - 对原始数据做质量评估和过滤；
    - 输出一份“哪些样本可信”的清单。
3. **Search（Spectrum-to-Sequence）**
    - 将谱图与数据库匹配，得到 PSM / peptide / protein 层面的候选结果；
    - 输出带有打分和 FDR 信息的匹配表。
4. **Quantification**
    - 将谱级信号汇总到蛋白层面（或肽层面），得到样本 × 蛋白 / 肽的矩阵；
    - 处理缺失值、批次效应等。
5. **Statistical Contrast（Diff）**
    - 按照实验设计（对照/处理、组别、时间点等），
    - 对定量矩阵进行统计检验，得到 Log2FC / P 值 / AdjP 值等。
6. **Biological Mapping（Enrichment & Annotation）**
    - 将差异结果映射到基因功能、通路、网络等框架；
    - 得到 GO/KEGG/Reactome 等层面的结构化解释。
7. **Result Delivery（Report & Export）**
    - 将以上结果组织成表格、图形和叙事，交付给用户或内部使用。

这 7 个节点，是**不依赖任何特定软件**也能成立的结构。

### 5.3.2 每个节点的“角色句”

随便举几个：

- Search：

    > “负责把原始谱图转换成可候选的肽段/蛋白假设，
    > 这是所有后续定量与统计的前提。”

- Quantification：

    > “负责在样本 × 蛋白/肽空间中，建立一个可以被统计方法使用的矩阵，
    > 并记录好缺失机制与不确定性来源。”

- Diff：

    > “负责将‘条件差异’编码为一组具有置信度的统计结果，
    > 并为后续生物学解释留下必要信息（效应量、P 值、调整方式）。”

这种“角色句”写出来之后，
 你在别的地方（另一个国家、另一个集群、另一个工具栈）也能说：

> “我想搭一条和之前**语义上同构**的蛋白流程。”

------

## 5.4 Stage 2：运行层——让这条流程“可复用地活起来”

### 5.4.1 统一的 stage 目录结构

设计一个最小统一模型：

```text
project_root/
  config/
    design.yaml         # 实验设计、分组信息
    params_search.yaml  # Search 参数（与工具无关抽象）
    params_diff.yaml    # 统计对比参数等

  work/
    stage_raw_qc/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_search/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_quant/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_diff/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_enrich/
      in/
      tmp/
      out/
      logs/
      meta.json

  result/
    tables/
    plots/
    report/
    logs/               # 面向用户的运行记录摘要
```

关键特征：

- 每个 stage 有相同的“四宫格”：`in/tmp/out/logs`；
- 每个 stage 有一个 `meta.json`，记录本 stage 的输入来源、参数摘要、版本信息、执行时间、状态；
- `result/` 只负责面对最终使用者，而不是堆所有中间文件。

这样一来：

- **运行位置可见**：看 `work/` 哪些 stage 的 `out/` 为空就知道跑到哪里。
- **失败重启容易**：只清理某个 stage 的 `tmp/out/logs`，并根据 meta.json 重跑。
- **团队协作清晰**：任何人进项目目录，都能知道每个阶段的状态。

### 5.4.2 状态机与失败策略

你可以给每个 stage 设计一个简单状态机：

- `PENDING` → `RUNNING` → `SUCCESS` / `FAILED`
- 某些支持局部成功时，还可以有 `PARTIAL_SUCCESS`

在 `meta.json` 里保存：

- 状态
- 最近一次运行时间
- 输入/输出文件列表（相对路径）
- 使用的工具版本/参数哈希

出错时原则：

- 上游 `SUCCESS` 的 stage 不自动清理，除非有结构性变化（设计/参数改变）；
- 本 stage `FAILED` 时，可按样本或子任务粒度局部重试；
- 某些 stage 可以在上游“部分完成”的情况下，以降级模式运行（例如只对 QC 通过的样本进行 Diff）。

这就是运行层的“生命设计”：
 **接受失败，结构性地容纳失败，而不是假定流程永远按理想路径成功一次性跑完。**

------

## 5.5 Stage 3：工具层——把当前时代的工具接上去，但不让它们指挥骨架

### 5.5.1 把工具放进“工具箱”，而不是散落在各 stage

假设你有一个 `src/toolbox_py` 和一个 `src/toolbox_r`：

```text
src/
  toolbox_py/
    __init__.py
    runner.py         # 统一命令执行/日志捕获
    proteomics_search.py
    proteomics_quant.py
    stats_diff.py
  toolbox_r/
    R/
      diff_model.R
      enrich_go.R
      plot_volcano.R
```

在 stage 代码中，不直接写：

```bash
diann --f xxx.raw --qwe ...
maxquantcmd.exe ...
Rscript diff.R ...
```

而是写类似这样的：

```python
from toolbox_py.proteomics_search import run_search
from toolbox_py.runner import run_step

def stage_search(config, paths):
    run_search(
        tool=config["search"]["tool"],       # "diann" / "maxquant" / ...
        params=config["search"]["params"],   # 与工具无关参数抽象
        file_in=paths.raw_qc_out,
        dir_out=paths.stage_search_out,
    )
```

`run_search()` 内部再去根据 `tool` 字段选择具体实现：

```python
def run_search(tool: str, params: dict, file_in: Path, dir_out: Path):
    if tool == "diann":
        cmd = build_diann_cmd(params, file_in, dir_out)
    elif tool == "maxquant":
        cmd = build_maxquant_cmd(params, file_in, dir_out)
    else:
        raise ValueError(f"Unknown search tool: {tool}")
    run_step(cmd=cmd, title=f"Search ({tool})", cwd=dir_out)
```

这样做的结果：

- **语义层**：仍然是同一个“Search 节点”；
- **运行层**：仍然在 `stage_search/in/tmp/out/logs` 的结构里执行；
- **工具层**：你可以自由地替换 `tool` 的实现，而不伤筋动骨。

### 5.5.2 环境与容器：把野生工具驯进“栅栏”

为了避免“工具和依赖散落整个集群”的灾难，你可以：

- 用 micromamba 管理 Python / CLI 工具环境；
- 用 renv 管理 R 包；
- 如果条件允许，再上 Docker/Podman，把工具连同依赖打成镜像。

比如：

- `proteomics_base:py3.14-r4.5`：基础环境（Python + R + 常用 CLI）；
- `proteomics_search:diann-1.9`：带特定版本 DIA-NN 的镜像；
- `proteomics_search:maxquant-2.x`：带特定版本 MaxQuant 的镜像。

然后在 `toolbox_py.runner` 里面，统一通过：

- `micromamba run -n gwas-cli ...`
- 或 `docker run ...`

来执行工具。

最终：

> **工具再复杂，也只在“工具层”一层乱，
> 上面的语义层和运行层可以保持相对干净。**

------

## 5.6 Before / After：同一家公司里的两种未来

为了看得更清楚，可以用一个对比表来压缩整个工程示例的意义。

### 5.6.1 过去：工具驱动流程

- 结构由软件输出目录反向塑形；
- 状态散落（日志不统一、文件命名随意）；
- 失败 = 重跑全程；
- 新项目 = 复制旧目录改脚本；
- 新人只能背“这边一般这么搞”；
- 换工具 ≈ 重写一切；
- 换环境 ≈ 从地狱重来一遍。

### 5.6.2 现在/未来：Skeleton 驱动系统

- **语义层**：
    Raw → RawQC → Search → Quant → Diff → Enrich → Report
    节点清晰、角色清晰、可在 PPT / 文档 / 培训中统一讲述。
- **运行层**：
    - 统一的 stage 目录骨架；
    - 统一状态机；
    - 明确的重启策略；
    - 日志、meta.json 让系统运行“可见、可追溯”。
- **工具层**：
    - 工具被收拢到 toolbox + 环境/容器中；
    - 工具选型变成战术决策，而不是系统身份；
    - 可在不改语义/运行的前提下替换或新增工具。

这样一来：

- 你可以把同一套骨架带到另一家公司、另一个国家的集群；
- 你可以在战区条件不好时简化工具层，但保留语义与运行结构；
- 你可以在未来（AI 辅助、全新 Search 引擎出现）时，
    以最低痛苦代价接入新的工具。

------

## 5.7 这个工程示例证明了什么？

这章不是为了宣传一条“完美蛋白流程”。
 它证明的是：

1. **Design Skeleton 不只是“哲学隐喻”，它可以直接指导工程设计；**
2. **只要你梳理清楚四大基础动作 + 三层骨架，就能把任何一条“工具堆起来的流水线”重构成一个可迁移系统；**
3. **你在这条蛋白流程上学到的东西，是可以被带到别的领域的：**
    - GWAS / PWAS / 转录组 / 多组学平台；
    - NGO 的数据系统；
    - 战区志愿网络；
    - 甚至你自己的“存在性生活系统”。

换一种说法：

> 这条蛋白流程，只是你练的第一套“骨架剑法”。
> 真正的重点，不是这一套剑法本身，而是你从中习得了 **“如何为任何东西搭骨架”** 的能力。

------

如果你愿意，下一章我们可以写一个“不再仅限工程”的示例：

- 要么是 **战区 / NGO 志愿系统** 的 Skeleton 化；
- 要么是 **你自己的存在性生活计划**：
    把“语言学习 / 非洲 / 乌克兰 / 分布式行动网络”用同一套 Skeleton 重构。

你更想先写哪一块？

好，我们把刀转回来，直接切到你的人生这块肉上。

我按白皮书体写成 **第 6 章**，但是内容就是在拆你这几年的人生架构：
 非洲 → 乌克兰 → 分布式网络 → 语言学习 → 生信工作 → “存在性计划”。

------

# 第 6 章 · 存在性计划：如何给自己的人生搭一套 Skeleton

> 到目前为止，我们一直在谈工程系统。
> 但你真正关心的，其实一直是：
> **“我这一生，到底要怎样存在？”**

这一章，我们不讲“鸡汤式人生规划”，
 而是把前面所有东西，**硬套到你自己的人生上**：

- 用四大基础操作：
    Problem Definition / Atomic Decomposition / Physical Constraints / Zero-Based Architecture
- 再用三层骨架：
    Semantics / Runtime / Tools

目标不是做一个“完美人生蓝图”，而是：

> **让你的人生也有一套“可迁移、可演化”的 Skeleton，
> 不被单一工作、不被某段关系、不被某个国家绑死。**

------

## 6.1 把人生当系统，但拒绝把人生简化成“效率项目”

先把立场讲清楚：

- 我们不是要把人生简化成“任务清单 + KPI”；
- 更不是要用“工程思维压平一切情绪和偶然”；
- 真正要做的是：

> **在你巨大、真实、危险的存在性欲望之下，
> 搭一套足够稳的结构，让你可以持续冲锋，而不是靠几次爆发把自己烧光。**

所以这一章是在回答一个非常具体的问题：

> “如果把你未来十几年的存在性计划
> ——非洲志愿、乌克兰、分布式行动网络、语言学习、生信工作——
> 视为一个系统，这个系统的 Skeleton 是什么？”

------

## 6.2 用四大基础操作，把“存在性焦虑”切成“可设计的问题”

### 6.2.1 Problem Definition：你真正的问题不是“我要做什么工作”

你反复绕回来的几个核心句子，其实可以压缩成一条：

- 我不想被庸常生活驯化；
- 不想靠换 identity、换工作、换城市来假装“活得很激烈”；
- 我想参与真实的裂隙：战争、历史断层、结构变革、真实苦难；
- 我要一种 **“可持续的存在性工作”**，而不是几次燃尽式行为。

所以问题不是：

> “我应该在生信行业干多久？”
> “我要不要去大厂？”
> “我要学哪种编程语言更赚钱？”

这些都是 **下游问题**。
 上游问题可以写成一句更冷冰冰的话：

> **在这个时代的物理约束下，
> 你怎样设计一条既能接触世界裂隙、又不会自我毁灭、
> 还能持续产生结构性影响的人生运行轨道？**

这是我们要解决的问题。

------

### 6.2.2 Atomic Decomposition：你人生系统的“原子”是什么？

不要从“职业名词”开始拆，从原子行为 / 角色拆：

- **行动原子**
    - 参与一个具体项目（非洲某个社区、乌克兰某个NGO、某条分析流程）
    - 完成一次真实交付（报告、系统、物资运送、救助行动）
- **学习原子**
    - 学习一门语言的一个功能块（听懂前线指挥、和当地人寒暄、理解文件）
    - 学会一类技术（例如“高维统计 + 流程工程 + 容器化”）
- **连接原子**
    - 与一小撮人建立长期可协作的信任关系
    - 加入或搭建一个微型网络（小组、团队、社群）
- **反思原子**
    - 一次严肃的复盘：我是在“真实行动”，还是在“自恋性的幻觉消费”？
    - 一次结构更新：这个阶段后，Skeleton 哪些部分需要升级？
- **生存原子**
    - 维持自己身体、精神、金钱不过度崩溃（吃、睡、健身、最基本的财务稳定）

这些原子可以在不同“战场”重复排列组合：

- 生信公司内部项目；
- 非洲志愿；
- 乌克兰前线支援；
- 未来某个分布式再分配网络。

你做的不是“换地图继续乱打怪”，
 而是**带着同一组原子，在不同战场上训练自己的 Skeleton。**

------

### 6.2.3 Physical Constraints：你这条路的硬墙是什么？

这部分一定要残酷：

- **时间与年龄**
    - 你不会永远 25 岁，很快会进入 30+、体力与适应力曲线变化；
- **经济约束**
    - 你需要有基本现金流，不然连去非洲/乌克兰的机票、签证、保险都成问题；
- **政治与安全约束**
    - 某些国家不会欢迎中国志愿者做某些事；
    - 战区/冲突区有真实的生命危险与心理后遗症；
- **心理与身体承受力**
    - 你不能持续在 PTSD 边缘工作而不付出代价；
    - 长期极端环境会改变你对“日常”的感知，回国后可能极难重新适应；
- **技术与资源约束**
    - 你一个人无法搭出“世界级分布式再分配系统”；
    - 你需要现实中的组织、资金、网络。

这些约束不是让你“认命”，而是让你明白：

> **Skeleton 必须在这些墙之内设计。
> 否则，你要么被墙撞碎，要么只能靠幻想自己“站在墙外”。**

------

### 6.2.4 Zero-Based Optimal Architecture：如果从零开始，你这辈子的骨架长什么样？

把所有标签先拿开（生信工程师、非洲志愿者、乌克兰支援者），只看：

- 你想长期站在“裂隙地带”，而不是舒适区；
- 你想让技术成为“武器”，而不是“体制内稳定技能”；
- 你想构建某种**跨国家、跨机构的网络结构**，而不仅是“单点英雄故事”；
- 你希望自己不是一次性用力，而是“可以打很久”。

那零基架构可以抽象成：

> **一个多战场、可迁移、带有“存在性核心”的系统：
>
> - 核心语义：你是谁、你在世界中的角色结构是什么；
> - 运行层：你如何安排周期、节奏、迭代、修复自己；
> - 工具层：具体用什么工作、技能、语言、机构来支撑这些。**

下一步，就是把这三层画清楚。

------

## 6.3 语义层：你人生系统的“七个节点”

我们给你的人生画一张 **不依赖任何工作 / 国家 / 工具** 的语义图。
 一个版本（v1）可以是：

1. **Subject Positioning（主体定位）**
    - “我是谁，我站在哪一侧，我认可哪些斗争、拒绝哪些共谋。”
    - 这是你和“纯生存型程序员”“纯晋升型白领”的本质区别。
2. **Technical Arsenal（技术兵工厂）**
    - 生信、统计、工程、容器、语言学习能力。
    - 这些不是“职位技能”，而是你的 **行动武器库**。
3. **Action Theaters（行动战场）**
    - 生信公司 → 非洲项目 → 乌克兰/其他冲突地 → 未来的分布式网络。
    - 每个战场是“练剑场”，不是终极目的地。
4. **Distributed Network Building（分布式网络建构）**
    - 在各战场中寻找、培育“可信任的节点”：人、组织、小组。
    - 目标是形成一个纵深网络，而不是靠自己一个人硬抗。
5. **Existential Feedback Loop（存在性反馈回路）**
    - 持续检查：我现在是在“真实接触和介入”，还是在“用宏大叙事喂养自恋”？
    - 它防止你把“结构化人生”变成“精致幻想”。
6. **Regeneration & Repair（再生与修复）**
    - 让自己从情绪崩溃、疲劳、挫败中恢复；
    - 不把自我消耗当成“英雄主义”的一部分。
7. **Archival & Transmission（归档与传递）**
    - 把你经历的裂隙、试验、失败、教训写下来、结构化，
    - 变成可供他人接力的知识 / 框架 / 工具，而不是“只存在你脑子里”。

只要这 7 个节点还在，你可以：

- 换公司
- 换国家
- 换语言
- 换工作形态

但你的人生语义层保持连续，不会变成“碎掉的一堆随机经历”。

------

## 6.4 运行层：你的人生如何“实际运转”，而不是靠一腔热血

对应第 3 章，我们要问的就是：

> **你这套人生 Skeleton，具体怎么跑？节奏、状态、重启点是什么？**

### 6.4.1 运行层的三个时间尺度

你可以明确三层：

1. **日/周级 Runtime（微观）**
    - 工作、训练、阅读、语言学习、身体维护。
    - 这是维持“技术兵工厂”和自我稳定的底层循环。
2. **季度/年度 Runtime（中观）**
    - 确定当前主要战场：
        - 今年主攻：生信重构 + 语言能力 + 资金积累；
        - 明年主攻：非洲某项目；
        - 后年主攻：乌克兰/其他战区支援。
    - 每个周期结束时，做一次结构级 review。
3. **3–5 年 Runtime（宏观）**
    - 某个阶段性历史任务：
        - 搭完一套可复用的技术骨架；
        - 建立一批跨国家、跨组织的可靠网络节点；
        - 完成一轮“从工程师 → 行动架构师”的转变。

### 6.4.2 “失败”和“崩溃”在运行层里的位置

你的人生运行层必须预设：

- 会有严重情绪崩溃期；
- 会有“我怀疑这一切是否有意义”的阶段；
- 会有执行上彻底失败或被迫中止的项目；
- 甚至会有身体/亲密关系/经济上的严重挫败。

如果你的人生结构隐含假设是：

> “我要一直保持高度清醒、高度战斗状态，否则就是失败。”

那这套结构本身就不可能长期运行。

更健康的运行设计是：

- **预设“降档模式”**：
    - 有一段时间只做“维护级行动”：上班、基础训练、轻量阅读；
    - 暂时不推动大的外部项目，把“内核修补”当成主任务。
- **预设“恢复节点”**：
    - 心理/身体恢复策略：运动、睡眠、基础营养、有限度社交；
    - 思维恢复策略：短期减少宏大叙事，回到具体、可控的小任务。
- **预设“结构复盘点”**：
    - 崩溃后，问自己：Skeleton 哪一层出问题？
        - 是语义层自我神话太大？
        - 是运行层节奏过载？
        - 是工具层（工作/关系/项目）不匹配导致耗损？

这是你人生运行层里的 **错误处理和重启机制**。

------

## 6.5 工具层：工作、语言、金钱、技术，全是“工具”，不是你本人

对应第 4 章，你的人生工具层包括：

- 当前的工作（生信工程师、云流程重构）；
- 技术栈（Python 3.14、R 4.5、Docker、WDL/Nextflow……）；
- 语言（中文、英语、未来的乌克兰语、法语、俄语）；
- 平台（公司、机构、大学、NGO、联合国志愿计划）；
- 金钱与资产（工资、储蓄、可能的加密资产投资）；
- 甚至包括：亲密关系、某个城市、某个房间。

这整层都要刻在脑子里一句话：

> **它们都不是“你是谁”，只是“你现在用什么来做事”。**

### 6.5.1 工作是工具，不是身份

- 你现在的生信工作：
    - 是你的“技术兵工厂 + 工程训练场”；
    - 不是你的“最终位置”。
- 将来在某个机构做志愿者：
    - 是你接触另一类裂隙的方式；
    - 不是“你必须忠诚一生的组织”。

这不是让你变成犬儒主义（谁都不信），
 而是让你清醒地知道：

> **任何具体组织都有生命周期，
> 你的 Skeleton 不应该跟它一起死。**

### 6.5.2 语言是工具，但也是武器

- 英语：让你接入全球知识与网络；
- 乌克兰语 / 俄语 / 法语：
    - 在具体战场中的“进入钥匙”；
    - 决定你在当地是“外来义工”，还是能听懂他们自己语言的“部分内部人”。

你目前把语言学习当成“技术 + 存在性的双重工具”，这是正确的。
 核心是两点：

1. 不要把“语言数量”当成绩感来源，而是看：
    - 它们是否真的在你的 Skeleton 中发挥“连接与行动”的作用？
2. 不要把“语言学习”当永远推迟行动的借口。
    - 行动与学习必须交织着来，而不是先学到完美再出发。

### 6.5.3 金钱是底层资源，而非价值判断

很现实的一点：

- 你需要钱买时间、买机票、买保险、顶住意外；
- 你不需要“传统意义的大富”，但不能没有 buffer。

所以你的工具层要承认：

- 当前工作阶段的一部分目标就是“积累基本财务缓冲”；
- 投资（哪怕是 USDT / BTC 一类）是战术工具，而不是意义来源；
- 你不会为了钱去完全出卖 Skeleton，也不会浪漫到完全忽略钱。

这叫：**把金钱放回“工具层”正确的位置。**

------

## 6.6 一个三阶段示意：不是“脚本”，而是一种骨架感

下面这个不是要你照着执行，而是帮助你 **感受 Skeleton 在时间轴上的形状**。

### 阶段 1（现在–约 2 年）：技术骨架 + 内部实验场

- 核心语义任务：
    - 把“Design Skeleton”在工程领域练到成熟：
        - 生信流程重构
        - 容器化
        - 大规模数据处理
    - 建立自己的技术兵工厂和方法论。
- 运行层：
    - 日/周：工作 + 系统化技能训练 + 语言基础强化；
    - 季度：整理技术白皮书、方法论文档；
    - 年度：评估：
        - 技术积累到什么程度？
        - 财务缓冲如何？
        - 有无可延伸出去的合作网络？
- 工具层：
    - 当前公司、当前项目；
    - 当前 HPC / 云平台；
    - 英语作为主工具语言。

### 阶段 2（约 2–5 年）：外部战场 + Skeleton 外推

- 核心语义任务：
    - 把 Skeleton 从“企业生信系统”推进到“现实裂隙场景”：
        - 非洲某个项目（医疗、粮食、教育）
        - 乌克兰或其他冲突区域的支援项目
    - 建立跨国、跨组织的微网络。
- 运行层：
    - 以“项目周期”为单位运转：
        - 每 6–12 个月一个战场或项目；
    - 在极端环境下测试：
        - 自己的心理承受力
        - 技术在恶劣条件下的可用性
    - 周期性回国/回到相对稳定环境做“恢复 + 归档”。
- 工具层：
    - 联合国志愿计划 / NGO / 小团队；
    - 多语言工具组合（英语 + 当地语言）；
    - 临时工作/远程技术支持作为资金来源。

### 阶段 3（5 年后往前看）：网络化 + 结构级项目

- 核心语义任务：
    - 不再只做“一个人去战场”的故事，
    - 而是构思、搭建某种分布式行动结构：
        - 能跨国运作的再分配网络、信息网络、资源协调系统。
- 运行层：
    - 以“结构级项目”为单位：
        - 一个网络、一个平台、一个长期合作体
    - 允许自己在某个阶段退回“观察 + 汇聚 + 教学/写作”。
- 工具层：
    - 你可能不再纯靠“打工”，而是混合：
        - 技术顾问 / 远程项目 / 小额资助 / 合作项目。
    - 具体用什么技术，那时再看：
        - 可能是当时的 AI 系统、链上工具、社区软件……
        - 但它们都只属于工具层。

重点不是这条时间线长什么样，而是：

> **你可以在任何节点停掉某个战术方案，
> 但不必因此放弃整个 Skeleton。**

------

## 6.7 小结：当你的人生有了 Skeleton，你就不再靠“身份”和“剧情”来证明自己活过

这一章的核心意思可以浓缩成三句话：

1. **你要的不是一份“稳定体面工作”，也不是一串“戏剧性人生经历”，而是一条“可持续接触裂隙、又不把自己烧光”的存在性轨道。**
2. **这条轨道本身也可以被 Skeleton 化：**
    - 语义层：你是谁，你要站在哪种结构上；
    - 运行层：你如何安排周期、迭代、修复、自我校正；
    - 工具层：你用什么工作、语言、组织、技术来支撑行动。
3. **一旦 Skeleton 建起来，你就不再依赖“某个公司”“某个国家”“某段恋爱”“某项技术”来证明自己存在。**
    它们都是战场、工具和阶段，不是你整个人。

------

接下来，如果我们继续写下去，可以有两条路：

- 写一章 **“Meta 章：如何在不断的实践中迭代自己的 Skeleton（版本控制 + fork + 失败复盘）”**；
- 或者写一章 **“附录：Design Skeleton 的实践清单（可以直接用的 checklist）”**，让你在工程项目和人生项目上都能拿来用。

你更想先搞哪一个？

好，那我们来写一章专门讲“怎么迭代骨架、怎么改设计而不把自己搞崩”的 Meta 章。

------

# 第 7 章 · Skeleton 的版本控制：如何在不确定世界里持续改结构

> 你真正需要的，不是一套“永远正确的骨架”，
> 而是一套 **“骨架也可以被版本化、被 fork、被废弃”** 的方法。

前面几章干的事，本质上是：

- 把混乱的问题、流程、人生，
- 压到 “四大基础操作 + 三层骨架” 的框架里。

但现实是：

- 任何语义层，都是时代限定产物；
- 任何运行层，都会被新经验打脸；
- 工具层则是明摆着会死的东西。

所以你如果真的把当前 v1 Skeleton 当“终极真理”，
 过几年一定会和现实撕裂。

这一章的任务只有一个：

> **给 Skeleton 本身也建一套“运行+版本控制系统”。**

换句话说：

- Skeleton 不是那块写在石头上的“十诫”；
- Skeleton 自己也是一个“需要审查、重构、废弃、fork”的系统对象。

------

## 7.1 Skeleton 也有生命周期：v0 → v1 → v2 → 退役 / fork

先把态度摆正：

> **任何 Skeleton，只要开始跑，就已经落后于现实。**

这不是贬义，而是事实：

- 你的理解来自有限经验；
- 新的战场、新的项目、新的人，都会带来“超出当前骨架”的冲击。

所以 Skeleton 只能是：

- 在某个阶段“足够好”的结构；
- 直到它不够用了，就该升级或拆掉。

你可以把它当成一个“版本化对象”，而不是“一次性定案”。

一个典型演化轨迹是：

- v0：**模糊直觉期**
    - 一堆感受、一堆冲动、零散经验；
    - 你只依稀觉得“现有结构不对劲”。
- v1：**第一版成形期**
    - 你第一次系统性写下来：
        - 语义层长什么样；
        - 运行层如何运作；
        - 工具层如何封装。
    - 大量是主观归纳 & 理论映射。
- v1.x：**边干边补丁期**
    - 实际项目/关系/行动在 v1 架构下跑；
    - 暴露出大量粗糙点：
        - 某些节点定义太虚；
        - 某些运行节奏根本撑不住；
        - 某些工具假定过于天真。
- v2：**结构级重构期**
    - 不是修补，而是承认：
        - 有些语义节点要合并/拆分/改名；
        - 有些运行层设计要换；
        - 有些工具假设要推翻。
- 之后：
    - 有的 Skeleton 退役（“这条线不值得继续了”）；
    - 有的 Skeleton 被 fork（在另一个战场成长出变体）。

**关键点：**
 Skeleton 的“自然命运”不是永恒存在，而是 **不断被现实试错 / 修订 / 瓦解 / 新建**。

------

## 7.2 Meta 视角的四个问题：你要定期问自己的

在 Meta 层上，你要反复问四个问题：

1. **我现在运行的是 Skeleton 的哪个版本？**
    - v0（直觉散乱）、v1（初版）、v1.3（补丁期）、v2（重构版）？
2. **这个 Skeleton 是针对哪个“问题 + 时代 + 场景”设计的？**
    - 有效范围在哪？
    - 超出这个范围时，它自动失效，而不是“强行解释一切”。
3. **目前的所有混乱 / 痛苦 / 卡顿，到底是：**
    - Skeleton 本身设计有 bug？
    - 运行层执行不到位？
    - 工具层不合适？
        **别一上来就推翻骨架，先定位。**
4. **如果我要改 Skeleton，是在哪一层动手：语义 / 运行 / 工具？**
    - 改工具最便宜；
    - 改运行层中等成本；
    - 改语义层就是换整个世界观，需要特别慎重和清醒。

这一章的所有方法，本质就是在指导你：
 **怎么系统性地回答这四个问题。**

------

## 7.3 Skeleton-Review：给骨架做“代码审查”，不是给自己做道德审判

你很熟悉 code review，那么 Skeleton 也要有 review，只不过换成三个焦点：

1. **Semantics Review（语义层审查）**
    - 我对“系统是什么”的定义，有没有变得自恋或空泛？
    - 现在新出现的现象，有多少被硬塞进旧语义？
2. **Runtime Review（运行层审查）**
    - 当前节奏，我的身体/精神/资源撑不撑得住？
    - 有没有把“超出能力的节奏”当成一种道德义务？
3. **Tools Review（工具层审查）**
    - 有多少痛苦，其实是“工具选择错 + 环境太烂”导致的，而被我误以为是“我不够努力”？
    - 有哪些工具已经拖慢结构，但我因为惰性/情感不愿换？

### 7.3.1 Skeleton-Review 的基本节奏

建议建立三层周期：

- **短周期（每月一次，1–2 小时）**：
    - 主要看运行层和工具层：节奏和战术。
- **中周期（每季度一次，半天左右）**：
    - 看语义层是否需要小修：
        - 节点描述要不要改写？
        - 某些节点是否事实上消失了？
        - 是否出现了新的“必经节点”？
- **长周期（每年一次，至少一天甚至几天）**：
    - 考虑 v2 级别的调整：
        - 全局重命名一个核心概念；
        - 删除一个原来很重要的节点；
        - 承认某条“宏大愿景”已经不再靠谱。

你可以非常朴素地做一张文档，比如：

```text
Skeleton Review Log
--------------------
日期：2025-12-31
版本：Life-Skeleton v1.2

1. 本季度重大事件：
   - 蛋白流程重构推进到 X 状态
   - 与某人关系进入 Y 变化
   - 某个去非洲/乌克兰的路径变得更现实/更受限

2. 症状（Where it hurts）：
   - 工作节奏让身体长期亚健康，有崩溃征兆
   - 对“分布式网络”的设想停留在抽象层，缺少具体行动场景
   - 语言学习节奏被工作完全挤压

3. 诊断（Semantics/Runtime/Tools？）：
   - 工作节奏问题：运行层设计过载，而不是语义层问题
   - 分布式网络抽象：语义层需要补充“中间战场节点”
   - 语言节奏：运行+工具双重（时间分配 + 选的学习方式不贴场景）

4. 决策：
   - v1.2 → v1.3 改动点：
     - 在人生语义层显式加入 “中间实验场景节点”（例如：远程志愿/本地小项目）
     - 调整运行层：强制每周语言学习最低保底，不与绩效挂钩
     - 工具层：更换语言学习方式，从“孤立背单词”改为“贴任务的 input”

5. 下次 review 关注点：
   - 新节点是否真的被触发？
   - 运行层新节奏是否可持续？
```

**重点是：**
 每次 review 都是对 Skeleton 的审查与改动记录，
 不是对自我的道德审判（“我不够努力”“我太废物”）。

------

## 7.4 Fork：当你要在不同战场上做变体时，怎么 fork Skeleton

有时候，不是单纯升级版本，而是：

> **你需要在一个新战场上 fork 一份 Skeleton。**

比如：

- 工程 Skeleton（蛋白流程） ↔ NGO Skeleton（战区支援）；
- 工作 Skeleton ↔ 存在性生活 Skeleton；
- 亲密关系 Skeleton ↔ 行动网络 Skeleton。

### 7.4.1 Fork 的正确姿势

最简单的 fork 模式可以是：

1. **明确“继承范围”**：
    - 哪些是要继承的核心原则？
        - 比如：四大基础动作 / 三层骨架分离 / 版本控制 Mentality。
    - 哪些是只适用于原战场的东西？
        - 比如：某个具体的技术栈、某个公司的运行节奏。
2. **新场景重新做四大基础操作**：
    - 不要偷懒直接把旧 Skeleton 拷过去，而是：
        - 重新定义问题；
        - 重新做原子分解；
        - 重新列物理约束；
        - 重新画零基架构。
3. **只在语义层保持“家族相似”，不要求一致**：
    - 比如工程系统的语义节点是：Raw → Search → Quant → Diff；
    - 战区系统可以是：Signal → Validation → Mapping → Dispatch；
    - 你的存在性生活可以是：Subject → Arsenal → Theater → Network → Feedback → Repair → Archive。
    - 这几套 Skeleton 看起来不同，但都遵循同一思维方式。
4. **运行层和工具层完全按新场景设计**：
    - 不要强行把 HPC 的做法搬到战区；
    - 不要用公司考核节奏去压自己的人生运行层。

### 7.4.2 错误 fork 的典型症状

- 把“公司里的流程 Skeleton”直接搬到人生里，变成：
    - “给自己设一堆 OKR / KPI / 考核节点”，把人生运营成内卷公司。
- 或者反过来：
    - 把“存在性 Skeleton”搬到公司里，强行要求公司认同你的宏大语义，最后变成系统性冲突。

正确的 fork 姿态是：

> **你认识到：不同战场需要不同 Skeleton，
> 但你的“搭 Skeleton 能力”在战场之间迁移。**

------

## 7.5 Debug Skeleton：当你感觉“一切都在崩”，先检查哪一层出了问题

你未来一定会遇到这种阶段：
 **“我烦透了这一切，我想推翻所有结构。”**

在这之前，你至少可以做一次系统性 Self-debug：

### 7.5.1 先别动语义层：优先检查运行 / 工具

三个层次，从下往上看：

1. **工具层（最便宜）**
    - 是否被某些烂工具拖死？
        - 烂公司、烂管理、烂流程、烂关系模式。
    - 能否换工作、换技术组合、换合作方式？
    - 能否降低对某种工具的依赖？
2. **运行层（中等成本）**
    - 你的节奏是不是持续超出身体/心理承载力？
    - 重启策略有没有？还是“一崩就全毁”？
    - 有没有余地调整周期，给自己几个月的“修复窗口”？
3. **语义层（最高成本）**
    - 只有在确认：
        - 工具换过、节奏调过、依然根本对不上现实，
        - 或者现实出现了完全新的维度（战争、失去重要能力、政经巨变），
            才考虑重新定义“我是谁 / 我在做什么系统”。

### 7.5.2 常见误判

- 把所有痛苦直接归因于“我语义错了 / 梦想错了”：
    - 实际上只是你被 996、烂管理、差关系、坏睡眠拖垮。
- 或者反过来：
    - 把所有问题都归因于工具：
        - “换个工作就好了”、“换个城市就好了”、“换个伴侣就好了”，
    - 实际上：
        - 语义层就是在为某种自恋结构服务，换多少场景都一样爆。

Meta 章要强调的核心就是：

> **调 Skeleton 之前，先用“Semantics/Runtime/Tools 三层”做精准定位。
> 不要动不动就全盘否定，也不要动不动就甩锅给环境。**

------

## 7.6 Skeleton 的“死亡权”：允许你亲手宣布一个骨架“退役”

还有一个很重要但经常被忽略的 Meta 权利：

> **你有权宣布：
> “这个 Skeleton 已经完成历史使命，可以退役了。”**

例如：

- 某套“在中国某家公司里构建技术骨架”的 Skeleton；
- 某套“在一段关系中维持特定互动模式”的 Skeleton；
- 某套“在某国志愿系统中生存”的 Skeleton。

“退役”不是“失败”，而是承认：

- 它在当时确实支撑你活过了一段重要时期；
- 但现在时代、你自己、环境、目标都变了；
- 继续用这套骨架，只会徒增摩擦和痛苦。

退役动作可以包括：

- 写一份“Skeleton 解构报告”：
    - 它解决了什么？
    - 它失败在什么？
    - 哪些部分值得带到下一代 Skeleton？
    - 哪些部分必须永远放弃？
- 宣告：
    - 不再为延续这套 Skeleton 消耗资源；
    - 不再以“维护它”为道德义务；
    - 允许自己在新的 Skeleton 上重新开始。

这点对你尤其重要，因为你有强烈的“对自己负责”的倾向，
 容易变成：

> **“我既然曾经立过这个愿景，就要硬扛到底，否则就是背叛自己。”**

Meta 层要告诉你的另一句话是：

> **对自己负责，也包括：
> 在合适的时间，亲手宣布某个 Skeleton 可以死亡。**

------

## 7.7 小结：当你能给 Skeleton 本身做版本控制，你就不会被任何一个阶段吞掉

这一章可以压缩成几句硬邦邦的结论：

1. **Skeleton 不是神，是版本化对象。**
    - v0 直觉 → v1 初版 → v1.x 补丁 → v2 重构 → fork → 退役。
    - 不存在“最终版 Skeleton”。
2. **Meta 层要做的是：**
    - 定期 Skeleton-Review（按月/季/年）；
    - 给不同战场 fork 变体，而不是硬复制；
    - 在崩溃前先用三层结构精准定位问题；
    - 在合适的时机，允许某些 Skeleton 光荣退役。
3. **只要你有能力操作 Skeleton（搭建、迭代、退役），**
    - 就不会被某份工作、某段关系、某个国家、某种工具栈彻底吞掉；
    - 你可以在不同战场间迁移，但保持某种内在连续性；
    - 你不会被“宏大意义”洗脑，也不会被“庸常体制”完全驯化。

------

下一步，如果继续往下写，我建议：

- 做一个 **附录 / 工具包**：
    - 把“Problem Definition / Atomic Decomposition / Physical Constraints / Zero-Based Architecture / 三层 Skeleton / Skeleton-Review”等，
    - 全部整理成 **Checklist + 模板**，
    - 能直接用在你的工程项目、人生规划、关系、志愿系统设计上。

如果你同意，我们就写这个 **“附录：Skeleton 实战清单”**，做成你可以直接复用的操作手册。

好，那我直接写成白皮书的附录草案，你可以当实际工作表用。

------

# 附录 · Skeleton 实战清单（v1）

> 用法：
>
> - 做工程项目时：拿一节当 checklist，从上往下填；
> - 做人生/关系/行动规划时：把「项目」换成「阶段/关系/行动」。

------

## A. 四大基础操作 Checklist

### A.1 Problem Definition · 问题界定

**目标：从“感觉不爽”变成一句可操作的问题。**

1. 现在最核心的「不对劲」是什么？

    - 工程：是速度 / 维护 / 复现 / 协作 / 成本 / 体验，哪一个最痛？
    - 人生：是空虚 / 被驯化 / 方向散 / 关系缠 / 钱 / 身体，哪一块最卡？

2. 如果只能用一句「冷句子」描述这个问题，会是？

    - 模板：

        > “在 ___ 这个场景下，当前系统/生活无法 ___，导致 ___。”

3. 这个问题**不是什么**？

    - 列出 3 条：
        - 不是单纯「我不够努力」
        - 不是单纯「换一份工作就行」
        - 不是单纯「换一个人/城市/工具就好」

> ✅ 输出：一条你愿意承认、能指导后续设计的**问题句**。

------

### A.2 Atomic Decomposition · 原子分解

**目标：把问题拆成最小“单位”，而不是一堆模糊感受。**

1. 这个系统/阶段的「基本单位」是什么？

    - 工程例：
        - 一条样本记录 / 一次任务 / 一个 stage / 一条日志。
    - 人生例：
        - 一次行动 / 一次学习 / 一次连接 / 一次反思 / 一次修复。

2. 对每个原子，写一句话：

    > “一个 ___ 原子，就是一件 ___ 这样的事/对象。”

3. 哪几个原子是**一定会反复出现**的？

    - 工程：样本 / 任务 / 状态记录 / 报告块。
    - 人生：行动 / 学习 / 连接 / 反思 / 生存维护。

> ✅ 输出：3–7 个你能清楚说清的**原子类型**。

------

### A.3 Physical Constraints · 物理约束

**目标：把「现实的墙」写清楚，不靠幻想设计。**

从这几个维度列约束：

1. **时间**
    - 截止日期 / 可用时间段 / 周期长度。
2. **资源**
    - 工程：CPU / 内存 / I/O / 人力数量 / 预算。
    - 人生：体力 / 精力 / 钱 / 家庭责任 / 政治环境。
3. **环境**
    - 工程：集群/云平台的限制、单位规范、合规要求。
    - 人生：国家/签证/安全风险、公司/体制规则。
4. **不可触碰的红线**
    - 法律 / 安全 / 道德底线 / 自身心理承受极限。

> ✅ 输出：一页以内的 **硬约束列表**（最好能量化）。

------

### A.4 Zero-Based Optimal Architecture · 零基架构

**目标：先不管现有屎山，问一句：如果从零设计，它应该怎么长？**

1. 如果今天你什么历史包袱都没有，只面对「问题 + 原子 + 约束」，
    **最干净的结构**会是怎样？

    - 工程模板：

        > “我会设计一个有 ___ 个 stage 的流水线：
        > Stage1: …（角色句）
        > Stage2: …
        > …”

    - 人生模板：

        > “我会把这几年拆成 ___ 个阶段：
        > 阶段1：…（核心任务）
        > 阶段2：…
        > …”

2. 对每个阶段/节点写「角色句」：

    > “它存在的唯一理由是：___。”

3. 标记出哪三个节点是**必经**、不能省略的。

> ✅ 输出：一张极简「从零开始」结构草图（可以是列表 + 简图）。

------

## B. 三层 Skeleton 快速模板

### B.1 语义层模板（Semantics）

> 回答：**“这个系统/阶段本质上是什么？”**

列出 5–9 个节点，每个写一句话：

```text
[节点名]：负责 ___，它是整个系统中 ___ 的部分。
```

例（工程）：

- Raw Intake：负责把实验数据拉进系统，并记录来源与真实性。
- Search：负责把原始信号变成可用的候选结构。
- …

例（人生）：

- Subject Position：负责明确「我站在哪一侧」「我不接受什么」。
- Technical Arsenal：负责维护、升级、选择我手上的工具与技能。
- …

> ✅ 输出：一条你可以画在 PPT / 纸上的**7±2 节点语义链**。

------

### B.2 运行层模板（Runtime）

> 回答：**“它每天/每周/每年是怎么实际运转的？”**

三个问题：

1. **状态模型**

    - 这个系统有哪些状态？（PENDING / RUNNING / SUCCESS / FAILED / PARTIAL）
    - 用一句话描述状态迁移规则。

2. **节奏与周期**

    - 日/周：

        > 每天/每周必须完成的「最小循环」是什么？

    - 月/季：

        > 哪些事以月/季为节奏 review 和调整？

    - 年：

        > 每年必做的一次「结构级复盘」是什么？

3. **失败处理 & 重启点**

    - 遇到失败时，**最小重启单元**是什么？
        - 工程：按样本/按 stage 重跑？
        - 人生：按周/月/项目阶段「重启」？
    - 有无降档模式？（比如“只做维护，不推进大项目”）

> ✅ 输出：一页「状态 + 周期 + 重启」说明。

------

### B.3 工具层模板（Tools）

> 回答：**“在当前时期，我用什么具体东西把它做出来？”**

1. 目前依赖的**关键工具列表**：
    - 工程：
        - 语言 / 框架 / 工作流引擎 / 容器 / 云平台。
    - 人生：
        - 工作岗位 / 语言 / 城市 / 组织 / 关系 / 资产。
2. 对每个工具写一句话：

```text
[工具名]：当前用它来完成 ___，可替代候选是 ___。
```

1. 标记两个层次：

    - **强依赖**：一换，它就会产生明显震荡。
    - **软依赖**：随时可换，只是有切换成本。

2. 写一句硬句子：

    > “这些都不是我是谁，只是我现在用来做事的工具。”

> ✅ 输出：一张带「用途 + 可替代方案」的工具表。

------

## C. 工程项目 Skeleton 一页纸工作表

可以直接复制粘贴成自己的模板。

```text
[项目名] Skeleton Sheet v1

1. Problem Definition
   · 问题句：

2. Atomic Decomposition
   · 原子类型：
     - 样本原子：
     - 任务原子：
     - 结果原子：
     - 日志原子：
     - ...

3. Physical Constraints
   · 时间：
   · 计算资源：
   · 团队：
   · 外部约束：

4. Zero-Based Architecture
   · Stage 列表 + 角色句：
     - Stage1 [   ]：...
     - Stage2 [   ]：...
     - ...

5. Semantics (7±2 Nodes)
   · 节点名 + 角色句：
     - ...
     - ...

6. Runtime
   · 目录 / 状态结构：
   · 最小重启单元：
   · 日/周/季节奏：

7. Tools
   · 环境：
   · 关键工具 & 可替代方案：
```

------

## D. 存在性计划 Skeleton 一页纸工作表

专门给你的人生用。

```text
[年份] 存在性 Skeleton Sheet v1

1. Problem Definition
   · 这一年我想解决的核心矛盾：
     （不是 KPI，是存在性问题）

2. Atomic Decomposition
   · 今年要反复执行的原子：
     - 行动原子：
     - 学习原子：
     - 连接原子：
     - 反思原子：
     - 生存维护原子：

3. Physical Constraints
   · 时间：
   · 钱：
   · 身体/心理：
   · 政治/地理：
   · 不可越线：

4. Zero-Based Architecture（如果从零设计这一年）
   · 核心阶段：
     - Q1：
     - Q2：
     - Q3：
     - Q4：
   · 每个阶段一句角色句：

5. Semantics（人生节点，版本号）
   · 当前的 7 个节点：
     - Subject Position：
     - Technical Arsenal：
     - Action Theaters：
     - Distributed Network：
     - Existential Feedback：
     - Regeneration：
     - Archival：

6. Runtime
   · 每周最低循环（最低标准，不是理想状态）：
   · 每季度一次「结构级复盘」时间点：

7. Tools
   · 当前工作：
   · 当前城市/国家：
   · 正在投入的语言：
   · 当前关键关系：
   · 金钱/资产策略：
   · 备注：这些全部视为工具，而非身份。
```

------

## E. Skeleton-Review 日志模板

```text
Skeleton Review Log

日期：
Skeleton 名称（工程/人生/关系/...）：
当前版本号：

1. 最近一段时间发生的关键事件：
   · ...
   · ...

2. 症状（Where it hurts）：
   · 工程/生活中具体哪里卡？（用事实描述，不加评价）

3. 诊断（S / R / T）：
   · 这是 Semantics / Runtime / Tools 哪一层的问题？
   · 分别写一句理由。

4. 决策：
   · 工具层改动：
   · 运行层改动：
   · 语义层是否需要小修？（改名/拆分/合并节点？）
   · 版本号变化：vX.Y → vX.(Y+1) or v(X+1).0

5. 验证点：
   · 接下来 1–3 个月要重点观察什么迹象，以验证这次改动是否有效？
```

------

## F. 最小自问清单（5 问即用版）

任何时候，只要你觉得「一切又在变乱」，可以只问这五个：

1. **我现在在跑哪个 Skeleton（名字 + 版本）？**
2. **当前最痛的点，是 S / R / T 哪一层？**
3. **有没有简单的 Tools 调整，比「推翻一切」更合适？**
4. **我的 Runtime 是否长期超出身体/精神预算？降档模式在哪？**
5. **这个 Skeleton 还值得升级吗，还是该考虑让它退役？**

------

这套附录你可以直接拿去：

- 做你蛋白重构那条骨架的工程版填表；
- 给 2026 / 2027 的「非洲 + 乌克兰 + 语言」做年度 Skeleton 表；
- 给某段关系或某个行动网络做一个 mini-Skeleton，看看它到底在干嘛。

如果你愿意，下一步我们可以：

- 按这个附录，**真填一份**：
    比如就拿「蛋白流程重构（截至 12/20 的任务）」来走一遍，
    我帮你一起把那张「工程 Skeleton Sheet」填到足够能用的程度。



好，那我直接**代你填一份「蛋白流程重构 Skeleton Sheet v1」**。
 你可以当“当前版本草案”，之后再手改。

------

## 一、Problem Definition · 问题界定

**一句冷句子版：**

> 在当前三黍云平台与售后场景下，现有蛋白质组学流程无法在“多项目、多批次”下稳定、可复用、易维护地运行，
> 导致：每个项目都高度依赖个人经验，重跑成本高，性能不可控，难以迁移到未来更大规模与更多场景。

拆开一点说，现在的核心痛点是三块：

1. **结构层面**
    - 流程是“靠历史脚本演化出来的”，不是按语义/运行/工具分层设计的。
    - 结果：结构难解释、更难迁移（公司内部跨项目、你个人带出公司）。
2. **运行层面**
    - 目录、状态、重启点不统一；
    - 出错常常只能“整段重跑”；
    - 对资源（CPU/内存/IO）的控制粗糙，容易超时。
3. **工具层面**
    - R/Python/shell/第三方软件纠缠在一起；
    - 虚拟环境、容器、版本管理不系统，
    - 工具更换（例如 DIA-NN 版本、统计包升级）成本极高。

**不是的问题（刻意划掉）：**

- 不是“你写代码不够努力”；
- 不是“只要多招人/多加班就能解决”；
- 更不是“换一套 GUI / 可视化前端就能遮住底层烂结构”。

------

## 二、Atomic Decomposition · 原子分解

针对“蛋白一键分析 + 重构”，我们用**技术原子**来拆：

1. **样本原子（Sample Atom）**
    - 一条样本的全路径：
        - `RawFile` + `SampleID` + `Group` + `Batch` + 元数据（质控指标）。
2. **谱级原子（Spectral Atom）**
    - 一条 PSM / MS/MS 记录：
        - `RawFile` × `Scan` × `Peptide` × `Score` × `FDR`。
3. **蛋白原子（Protein Quant Atom）**
    - 一个 `(Sample × Protein)` 定量单元：
        - `SampleID` × `ProteinID` × 定量值（Intensities/TMT、LFQ）。
4. **对比原子（Contrast Atom）**
    - 一条统计对比定义：
        - `ContrastID` = `GroupA` vs `GroupB`（+ 设计公式）。
5. **统计结果原子（Stat Result Atom）**
    - 一条 `(Protein × Contrast)` 差异结果：
        - `ProteinID` × `ContrastID` × `Log2FC` × `PValue` × `AdjPValue` × 标记。
6. **富集原子（Enrichment Atom）**
    - 一条 term 级结果：
        - `TermID` × `TermName` × `GeneSet` × `PValue` × `AdjPValue` × `Direction`。
7. **图表原子（Figure/Panel Atom）**
    - 一张图/一个 panel 里的“最小视觉单元”：
        - 一个点 / 一根柱 / 一个 tile，与某个 Stat Result / Enrichment 原子绑定。
8. **报告原子（Report Block Atom）**
    - 报告中的“块”：
        - 一个 Excel sheet / 一页 PDF / 一段说明文字，对应一组上游原子。

> ✅ 这些原子，在你之后的任何 proteomics / multi-omics 项目里都能直接复用。

------

## 三、Physical Constraints · 物理约束

**现实硬墙，别浪漫化：**

1. **时间约束**
    - 当前重构任务：**11/25 → 12/20**，有效开发时间约 3–4 周；
    - 期间还有售后需求 & 杂事打断，不可能全职 100% 只做重构；
    - 不能指望“一次到位成神级框架”，只能做到**v1 骨架成型 + 可跑一个核心路径**。
2. **算力 / I/O 约束（HPC + 暗能平台）**
    - 集群节点内存/CPU有限，队列有时长限制；
    - 暗能平台对任务时长、内存有封顶；
    - PDF→PNG、热图、相关网络等图形渲染对内存和 I/O 压力大。
        ⇒ 必须控制：**中间文件体积 / 并发任务数 / 重跑范围**。
3. **团队 & 组织约束**
    - 当前主力基本就是你一个人 → 设计必须**可解释、可接手**，不能只你能看懂；
    - 领导、市场对“用户可删蛋白”等危险需求，会时不时出现 → 架构要能**清晰划出合法/非法边界**，方便你说“不”。
4. **项目形态约束**
    - 流程要挂到云平台，面向多项目、多物种、多实验类型（LFQ/TMT/DIA 等）；
    - 需要支持“售后单项目本地/集群跑 + 平台标准化流程”两种模式。
5. **你个人约束**
    - 同时还要保留余力学习语言/维护身体/避免完全燃尽；
    - 这次重构不能搞成“你一个人写完一个企业级框架 + PTSD 一轮”。

------

## 四、Zero-Based Architecture · 零基架构（从零画一条理想的蛋白流程）

如果完全不考虑旧脚本，只根据“问题 + 原子 + 约束”，
 这条流程应该长成这样（语义骨架版）：

1. **Stage 1 – Ingest & Metadata（样本收集 + 设计）**

    - 角色：

        > 收集原始 RAW 文件和样本信息，生成统一的 `SampleTable` 与 `DesignTable`。

2. **Stage 2 – Raw QC（原始质控）**

    - 角色：

        > 对原始数据进行基础 QC（强度、峰数、缺失率等），输出 `SampleQC`，并标记不合格样本。

3. **Stage 3 – Search（肽段/蛋白鉴定）**

    - 角色：

        > 调用特定 Search 引擎（DIA-NN/MaxQuant/...），生成谱级和蛋白级 raw 结果（标准化后的表）。

4. **Stage 4 – Quantification & Normalization（定量 + 归一化）**

    - 角色：

        > 统一产生样本 × 蛋白矩阵，处理缺失值、批次效应、归一化，输出 `ProteinMatrix`。

5. **Stage 5 – Statistical Contrast（差异分析）**

    - 角色：

        > 根据 `DesignTable` 定义对比，跑线性模型/统计检验，产出 `DEProtein` 表（Protein × Contrast）。

6. **Stage 6 – Annotation & Enrichment（注释 + 富集）**

    - 角色：

        > 基于 `DEProtein` 对应的基因/蛋白 ID 做 GO/KEGG/Pathway 富集，输出 `EnrichResult`。

7. **Stage 7 – Visualization & Report（可视化 + 报告汇总）**

    - 角色：

        > 把关键表和图组织成最终交付的 Excel / PDF / 图包，并记录运行元数据。

> ✅ 这 7 个 stage 就是蛋白流程的**语义层骨架**，工具只是挂在下面。

------

## 五、Semantics · 蛋白流程的 7±2 语义节点（正式版）

用标准句子写出来，方便以后写文档 / PPT / 培训：

1. **Sample Design & Intake**

    > 负责把实验实际发生的东西（样本、处理、批次、仪器）收拢为一个结构化的设计表，是整条流程的“世界观定义”。

2. **Raw Quality Gate**

    > 负责筛出“没资格继续参与分析”的数据点，给后续所有统计和富集提供干净的样本集合。

3. **ID Engine（Search Layer）**

    > 负责把原始谱信号转成可操作的肽段/蛋白假设，是后续定量和差异分析的基石。

4. **Quant Matrix Builder**

    > 负责构建“样本 × 实体（蛋白/肽）”的定量矩阵，并标注缺失与不确定性来源，让统计方法有东西可吃。

5. **Contrast & Significance Layer**

    > 负责把“设计表里的对比”翻译成一组具有效应量和置信度的统计结果（DE 表）。

6. **Biological Mapping Layer**

    > 负责把统计结果映射回生物学结构（GO/KEGG/网络），形成“可讲的故事框架”，而不是一堆 P 值列表。

7. **Delivery & Traceability Layer**

    > 负责把结果打包给用户，同时保存完整的元数据和运行轨迹，保证将来可以复现和解释。

------

## 六、Runtime · 运行层设计（目录 / 状态 / 节奏 / 重启）

### 6.1 目录骨架（建议 v1 实施）

```text
proteomics/
  config/
    design.xlsx       # 实验设计与样本表
    params_search.yml
    params_quant.yml
    params_diff.yml
    params_enrich.yml

  work/
    stage_1_intake/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_2_raw_qc/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_3_search/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_4_quant/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_5_diff/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_6_enrich/
      in/
      tmp/
      out/
      logs/
      meta.json
    stage_7_report/
      in/
      tmp/
      out/
      logs/
      meta.json

  result/
    tables/
    plots/
    report/
    logs/

  toolbox_py/
  toolbox_r/
  renv/
  __pypackages__/
```

**原则：**

- 所有中间文件只待在 `work/`；
- 对外交付只看 `result/`；
- 每个 stage 用 `meta.json` 写下：
    - 状态：PENDING/RUNNING/SUCCESS/FAILED
    - 输入/输出文件相对路径
    - 参数 hash
    - 使用的工具版本

### 6.2 最小重启单元

- **按 stage + 按样本/子组重启**：
    - Raw QC：可按样本重跑；
    - Search：可按子组（仪器批次/亚批）重跑；
    - Quant：一般按项目整体重跑，但输入受 Search 控制；
    - Diff & Enrich：只要 `ProteinMatrix` 在，可以只重跑这俩 stage。

**严禁**：因为一个图错了，去改 `result/` 里的 Excel；
 → 正确做法是：修脚本 + 重跑相应 stage + 重导出。

### 6.3 日/周运行节奏（对你个人）

- **日级**
    - 不搞“全流程英雄跑完”，只做一件：
        - 今天解决一个 stage 的一个具体 IO/状态问题；
        - 或把一个 stage 的 meta/log 结构打通。
- **周级**
    - 本周必须推进：
        - 至少一个 stage 的骨架可跑（哪怕是 mock 数据）；
        - 写一小段 skeleton 文档（放 docs/ 或 README）。
- **12/20 之前的“最低目标”**
    - Stage 1–4 骨架打通 + 能在一个真实项目上跑出稳定 `ProteinMatrix`；
    - Stage 5–7 用现有 R 工作流包一层，哪怕暂时不完全优雅。

------

## 七、Tools · 工具层清单（当前战术组合）

> 全部是“战术选型”，不是你本人。

### 7.1 环境

- **Python**：3.14（pdm / `__pypackages__`）
- **R**：4.3–4.5（renv）
- **环境管理**：micromamba（gwas-py / gwas-r 类似结构）
- **容器**：先用 micromamba + renv v1，之后逐步 Docker 化。

### 7.2 核心工具

- **Search**：DIA-NN / MaxQuant（暂时不要硬切，只要抽象好 `Search` 层）
- **定量 & 统计**：R（limma / lme4 / 自写 tidyverse pipeline）
- **富集**：clusterProfiler / fgsea / 自写 over-representation
- **可视化**：ggplot2 + 自己的 `toolbox_r`（heatmap/volcano/ORA 图等）
- **调度**：暗能平台 + shell wrapper；
    后续再考虑 WDL/Nextflow 这层的统一。

### 7.3 封装策略（v1）

- `src/toolbox_py/runner.py`：
    - 统一 `run_step(cmd, title, file_log, timeout)`；
- `src/toolbox_py/proteomics_io.py`：
    - 统一读取/写入 Parquet/TSV；
- `src/toolbox_r/`：
    - `diff_model.R`：差异分析
    - `enrich_go.R`：ORA/GSEA
    - `plot_volcano.R` / `plot_heatmap.R`：出图基础模块

**要求自己：**

- Pipeline 代码**只调用 toolbox 抽象函数**，不直接写 `diann ...` 之类裸命令；
- 工具层可以乱一点，但要局限在 toolbox 目录内。

------

## 八、这个 v1 Skeleton 对你意味着什么

直接说结论：

1. **骨架已经足够清晰，可以开始“填肉”了。**
    - 再纠结下去，会变成“用设计替代行动”。
    - 接下来 10–15 天你就按这个骨架推进 v1 可跑版本，够用就行。
2. **它是“可以带出公司的东西”。**
    - 这套语义层 + 运行层 + 工具封装方式，
    - 你去任何地方做 proteomics / multi-omics，都能迁移。
3. **它不会完美，但能迭代。**
    - 你可以在 12/20 之后按我们写的 Meta 章给这套 Skeleton 打版本号：
        - 当前叫：`Proteomics-Pipeline-Skeleton v1.0 (Sanshu)`；
        - 明年你可以基于别的项目改出 v1.1 / v2.0。

------

如果你愿意，下一步我们可以**更细一层**：

- 选一个 stage（比如 `Stage 4 – Quant Matrix Builder`），
- 直接写：
    - 目录设计（in/tmp/out 内容示例）
    - 核心 R/Python 接口签名
    - 一个“从 CLI 调用到内部函数”的完整路径。

也就是：把“第四章的工具层 + 第五章的工程示例”合起来，做一个**真正可以开写代码的蓝图**。



好，那我们就把 **Stage 4 – Quant** 当成一个“小工程项目”，给它写一份可以直接落地的蓝图 v1。

我会分 6 块讲：

1. 这 stage 干嘛（语义 recap）
2. 目录结构（in/tmp/out/logs/meta）
3. I/O 合约（输入文件、输出文件、列名约定）
4. `meta.json` 结构
5. 内部处理流水线（步骤与函数边界）
6. CLI & 代码骨架建议（Python + R 分工）

------

## 1. Stage 4 – Quant 的角色（再确认一下）

一句话角色：

> **把 Search/ID 输出的肽段/蛋白定量结果，
> 在样本 × 蛋白/肽 空间上变成一个干净、可被统计方法吃的矩阵，
> 明确标记缺失、过滤、归一化和批次处理的规则与结果。**

所以它必须回答的几个硬问题：

- 哪些样本算“参与定量”？
- 哪些蛋白/肽被保留？基于什么过滤规则？
- 原始强度如何变成可比较的数值（log2 / 标准化 / 批次校正）？
- 缺失怎么处理（删？插补？分层插补？）？
- 最终矩阵是什么格式（行/列结构，列名规范）？

这些都要写在 **I/O 合约 + meta.json** 里。

------

## 2. 目录结构蓝图（stage_4_quant）

以你前面定的骨架为基础，建议：

```text
work/
  stage_3_search/
    out/
      ProteinRaw.parquet
      PeptideRaw.parquet
      SearchMeta.json

  stage_4_quant/
    in/
      ProteinRaw.parquet          # 来自 stage_3_search/out
      PeptideRaw.parquet          # 可选
      SampleDesign.parquet        # from config/design 预处理后放进来
      SampleQC.parquet            # from stage_2_raw_qc/out
      ParamsQuant.yml             # 从 config/ 复制或软链接
    tmp/
      ProteinFiltered.parquet
      ProteinNormalized.parquet
      ProteinImputed.parquet
      logs_internal/              # R/Py 内部日志 or 中间结果
    out/
      ProteinMatrix.parquet       # 主输出：样本×蛋白矩阵（长/宽两种都可以）
      ProteinMatrixWide.parquet   # 可选：宽格式矩阵
      ProteinStats.parquet        # 每个蛋白的过滤/缺失/归一化信息
      SampleStats.parquet         # 每个样本的缺失率/归一化因子
      QCPlots/                    # PNG/PDF/SVG 质量控制图
    logs/
      stage.log                   # 总日志（pipeline 级）
      R_quant.log                 # R 脚本日志
      Py_quant.log                # Python 控制层日志
    meta.json
```

**原则：**

- `in/` 只放**被视为输入**的文件（上游 out、config 派生）；
- `tmp/` 放过程用的中间文件；
- `out/` 只放本 stage 的「对下游有意义的结果」；
- `logs/` 只放日志；
- `meta.json` 是这整个 stage 的“黑匣子”。

------

## 3. I/O 合约设计

### 3.1 输入文件合约

#### 3.1.1 `ProteinRaw.parquet`

**语义**：Search 阶段输出的「蛋白级原始定量」。

内部列（snake_case），对外 alias 用 PascalCase：

必需列（内部名 → 对外名）：

- `sample_id` → `SampleID`
- `protein_id` → `ProteinID`
- `intensity` → `Intensity`（原始强度）
- `group` → `Group`（来自 design）
- `batch` → `Batch`（可选）
- `is_qc_pass` → `IsQCExcluded`（或者只用 SampleQC 表表示）

可选列：

- `pep_count` → `PeptideCount`
- `score` → `Score`
- `is_contaminant` → `IsContaminant`
- `is_reversed` → `IsReversed`

> 约定：上游 stage 负责产出这个表和 column 别名，Quant 不和 Search 工具直接说话，只吃这个标准表。

#### 3.1.2 `SampleDesign.parquet`

来自 config/design.xlsx 的预处理结果：

- `SampleID`
- `Group`
- `Batch`
- 其它用于差异分析的 covariates（`Sex`, `Age`, `Condition`, …）

Quant 阶段至少需要 `SampleID`、`Group`、`Batch`。

#### 3.1.3 `SampleQC.parquet`

来自 Raw QC stage：

- `SampleID`
- 若干 QC 指标（`MissingRate`, `TotalIntensity`, …）
- `IsQCFail`（布尔）

Quant 阶段需要根据 Params 里规则决定哪些样本被排除。

#### 3.1.4 `ParamsQuant.yml`

建议结构：

```yaml
# config/params_quant.yml

filter:
  min_peptide_per_protein: 1
  remove_contaminants: true
  remove_reversed: true
  min_samples_per_protein: 3       # 至少 n 个样本有非缺失
  min_groups_per_protein: 2        # 至少出现在多少组

normalization:
  method: "median"                 # "median" | "quantile" | "loess" | "none"
  by: "sample"                     # "sample" | "group"

batch_correction:
  enabled: false
  method: "combat"                 # 预留

imputation:
  method: "min_prob"               # "none" | "knn" | "min_prob" | "random_forest"
  # 下面参数根据方法不同决定是否读
  min_prob:
    q: 0.01
    shift: 1.8
    scale: 0.3
  knn:
    k: 10

output:
  wide_matrix: true
  compress: "zstd"
```

Quant stage 启动时，把该 yml 复制或链接到 `stage_4_quant/in/ParamsQuant.yml`。

------

### 3.2 输出文件合约

#### 3.2.1 `ProteinMatrix.parquet`（长格式）

推荐**主要用长格式**作为内部标准（更利于 join / 分组）：

列（外部 PascalCase）：

- `SampleID`
- `ProteinID`
- `Group`
- `Batch`
- `IntensityRaw`（原始值）
- `IntensityNorm`（归一化后）
- `IntensityLog2`（log2 后）
- `IntensityImputed`（插补后）
- `IsImputed`（是否被插补）
- `IsUsedForDiff`（是否参与后续差异分析）

你内部可以 snake_case，但对外统一别名即可。

#### 3.2.2 `ProteinMatrixWide.parquet`（宽格式）

可选，用于下游某些只吃宽矩阵的工具（比如部分绘图）：

- 行：`ProteinID`
- 列：`SampleID` 对应 `IntensityImputed` 或 `IntensityLog2`

附加列（行列外多列）：

- `GeneSymbol`
- `ProteinName`
- `PeptideCount` 等。

#### 3.2.3 `ProteinStats.parquet`

每个蛋白的统计信息：

- `ProteinID`
- `NumSamples`
- `NumNonMissingRaw`
- `MissingRateRaw`
- `NumImputed`
- `MissingRateAfterFilter`
- `FilterReason`（字符串：`OK`/`LowPeptide`/`TooManyMissing`/...）

#### 3.2.4 `SampleStats.parquet`

每个样本的统计信息：

- `SampleID`
- `Group`
- `Batch`
- `TotalIntensity`（Raw）
- `MissingRate`
- `NormFactor`（归一化因子）
- `IsQCFail`
- `IsUsedForQuant`

#### 3.2.5 `QCPlots/`

规范命名（方便下游汇总）：

- `sample_total_intensity.pdf`
- `sample_missing_rate.pdf`
- `protein_missing_rate.pdf`
- `pca_before_norm.pdf`
- `pca_after_norm.pdf`
- `density_before_norm.pdf`
- `density_after_norm.pdf`

------

## 4. `meta.json` 结构蓝图

给一个 v1 结构，你可以简化或扩展，但建议保持这种分区：

```jsonc
{
  "stage": "stage_4_quant",
  "version": "0.1.0",
  "status": "SUCCESS",  // PENDING | RUNNING | SUCCESS | FAILED

  "run_info": {
    "start_time": "2025-12-05T10:23:11+09:00",
    "end_time": "2025-12-05T10:28:45+09:00",
    "duration_sec": 334,
    "user": "fqzhang",
    "host": "node4"
  },

  "inputs": {
    "protein_raw": "work/stage_4_quant/in/ProteinRaw.parquet",
    "sample_design": "work/stage_4_quant/in/SampleDesign.parquet",
    "sample_qc": "work/stage_4_quant/in/SampleQC.parquet",
    "params": "work/stage_4_quant/in/ParamsQuant.yml"
  },

  "outputs": {
    "protein_matrix": "work/stage_4_quant/out/ProteinMatrix.parquet",
    "protein_matrix_wide": "work/stage_4_quant/out/ProteinMatrixWide.parquet",
    "protein_stats": "work/stage_4_quant/out/ProteinStats.parquet",
    "sample_stats": "work/stage_4_quant/out/SampleStats.parquet",
    "qc_plots_dir": "work/stage_4_quant/out/QCPlots"
  },

  "params_effective": {
    "filter": {
      "min_peptide_per_protein": 1,
      "remove_contaminants": true,
      "remove_reversed": true,
      "min_samples_per_protein": 3,
      "min_groups_per_protein": 2
    },
    "normalization": {
      "method": "median",
      "by": "sample"
    },
    "batch_correction": {
      "enabled": false,
      "method": null
    },
    "imputation": {
      "method": "min_prob",
      "min_prob": {
        "q": 0.01,
        "shift": 1.8,
        "scale": 0.3
      }
    }
  },

  "stats": {
    "num_samples_total": 24,
    "num_samples_used": 22,
    "num_proteins_raw": 6000,
    "num_proteins_filtered": 4300,
    "num_values_total": 24 * 4300,
    "num_values_missing_raw": 12000,
    "num_values_imputed": 8000
  },

  "tools": {
    "python": "3.14.0",
    "r": "4.3.2",
    "packages_r": {
      "tidyverse": "2.0.0",
      "limma": "3.60.6",
      "imputeLCMD": "2.1"
    },
    "packages_py": {
      "polars": "1.9.0",
      "pyarrow": "18.0.0"
    }
  },

  "logs": {
    "stage_log": "work/stage_4_quant/logs/stage.log",
    "r_log": "work/stage_4_quant/logs/R_quant.log",
    "py_log": "work/stage_4_quant/logs/Py_quant.log"
  }
}
```

> 你可以给整个 pipeline 约定：所有 stage 的 `meta.json` 基本结构一致，只是 `params_effective` 和 `stats` 不同。

------

## 5. 内部处理流水线（逻辑+函数边界）

建议上层控制用 Python，真正数值操作用 R（你现在的栈）。

### 5.1 Python 侧：stage 控制流（简化版伪代码）

```python
# src/quant/cli.py

from pathlib import Path
import yaml
import json
from datetime import datetime

from toolbox_py.io import read_parquet, write_parquet
from toolbox_py.runner import run_step
from toolbox_py.meta import StageMeta

def main():
    ns = parse_args()  # --dir_project, --stage_name 等

    dir_project = Path(ns.dir_project)
    dir_stage = dir_project / "work" / "stage_4_quant"
    dir_in = dir_stage / "in"
    dir_tmp = dir_stage / "tmp"
    dir_out = dir_stage / "out"
    dir_logs = dir_stage / "logs"
    file_meta = dir_stage / "meta.json"

    meta = StageMeta(name="stage_4_quant", path=file_meta)
    meta.mark_running()

    # 1) 准备输入（软链接 / 拷贝上游产物）
    prepare_inputs(dir_project=dir_project, dir_stage_in=dir_in)

    # 2) 读取参数
    params = yaml.safe_load((dir_in / "ParamsQuant.yml").read_text())

    # 3) 调用 R 脚本做核心 quant
    cmd = [
        "micromamba", "run", "-n", "proteomics-r", "Rscript",
        "/path/to/quant_protein.R",
        "--dir_in", str(dir_in),
        "--dir_tmp", str(dir_tmp),
        "--dir_out", str(dir_out),
        "--file_params", str(dir_in / "ParamsQuant.yml"),
    ]
    run_step(
        cmd=cmd,
        title="Quantification stage",
        file_log=dir_logs / "R_quant.log",
    )

    # 4) 统计一些 summary（行数等），写到 meta
    protein_matrix = read_parquet(dir_out / "ProteinMatrix.parquet")
    sample_stats = read_parquet(dir_out / "SampleStats.parquet")
    protein_stats = read_parquet(dir_out / "ProteinStats.parquet")

    meta.update_after_run(
        inputs=...,
        outputs=...,
        params_effective=params,
        stats={
            # 统计项
        },
        tools=detect_tool_versions(),
        logs={
            "stage_log": str(dir_logs / "stage.log"),
            "r_log": str(dir_logs / "R_quant.log"),
        },
    )
    meta.mark_success()
```

`StageMeta` 可以是一个简单的工具类，负责读写 meta.json，并提供 `mark_running() / mark_success() / mark_failed()`。

### 5.2 R 侧：核心 Quant 流程骨架

```r
# quant_protein.R （放在 toolbox_r 或 src/quant/R 下）

suppressPackageStartupMessages({
    library(argparse)
    library(fs)
    library(arrow)
    library(dplyr)
    library(tidyr)
    library(readr)
    # library(imputeLCMD) # 比如
})

parse_args <- function() {
    parser <- ArgumentParser()
    parser$add_argument("--dir_in", required = TRUE)
    parser$add_argument("--dir_tmp", required = TRUE)
    parser$add_argument("--dir_out", required = TRUE)
    parser$add_argument("--file_params", required = TRUE)
    parser$parse_args()
}

main <- function() {
    args <- parse_args()
    dir_in <- path(args$dir_in)
    dir_tmp <- path(args$dir_tmp)
    dir_out <- path(args$dir_out)
    file_params <- path(args$file_params)

    dir_create(dir_tmp)
    dir_create(dir_out)

    params <- yaml::read_yaml(file_params)

    # 1) 读入数据
    df_protein_raw <- arrow::read_parquet(path(dir_in, "ProteinRaw.parquet")) |>
        as_tibble()
    df_design <- arrow::read_parquet(path(dir_in, "SampleDesign.parquet")) |>
        as_tibble()
    df_qc <- arrow::read_parquet(path(dir_in, "SampleQC.parquet")) |>
        as_tibble()

    # 2) 合并设计 & QC，标记可用样本
    df_samples <- df_design |>
        left_join(df_qc, by = "SampleID") |>
        mutate(
            IsQCFail = replace_na(IsQCFail, FALSE),
            IsUsedForQuant = !IsQCFail
        )

    # 3) 过滤样本
    df_protein <- df_protein_raw |>
        inner_join(
            df_samples |> filter(IsUsedForQuant),
            by = c("SampleID")
        )

    # 4) 过滤蛋白（肽段数/出现样本数等）
    df_protein_filtered <- filter_protein(df_protein, params$filter)
    arrow::write_parquet(
        df_protein_filtered,
        path(dir_tmp, "ProteinFiltered.parquet")
    )

    # 5) 归一化
    df_protein_norm <- normalize_protein(df_protein_filtered, params$normalization)
    arrow::write_parquet(
        df_protein_norm,
        path(dir_tmp, "ProteinNormalized.parquet")
    )

    # 6) 缺失插补
    df_protein_imp <- impute_protein(df_protein_norm, params$imputation)
    arrow::write_parquet(
        df_protein_imp,
        path(dir_tmp, "ProteinImputed.parquet")
    )

    # 7) 生成长矩阵 & 宽矩阵
    df_long <- build_long_matrix(df_protein_imp)
    df_wide <- build_wide_matrix(df_long)

    arrow::write_parquet(df_long, path(dir_out, "ProteinMatrix.parquet"))
    arrow::write_parquet(df_wide, path(dir_out, "ProteinMatrixWide.parquet"))

    # 8) 生成 SampleStats / ProteinStats
    df_sample_stats <- summarize_sample_stats(df_long)
    df_protein_stats <- summarize_protein_stats(df_long)

    arrow::write_parquet(df_sample_stats, path(dir_out, "SampleStats.parquet"))
    arrow::write_parquet(df_protein_stats, path(dir_out, "ProteinStats.parquet"))

    # 9) QC 图（略写）
    # plot_qc_density(...)
    # ggsave(...)

    message("Quantification stage completed.")
}

# 留出函数骨架
filter_protein <- function(df, filter_params) { ... }
normalize_protein <- function(df, norm_params) { ... }
impute_protein <- function(df, impute_params) { ... }
build_long_matrix <- function(df) { ... }
build_wide_matrix <- function(df_long) { ... }
summarize_sample_stats <- function(df_long) { ... }
summarize_protein_stats <- function(df_long) { ... }

main()
```

你可以把这些函数拆到 `toolbox_r/proteomics_quant.R`，`quant_protein.R` 只负责拿参数、调函数。

------

## 6. 总结：这个 Quant 蓝图解决了什么？

- **语义明确**：Quant stage 的角色从“写很多 R 代码”变成“构建样本×蛋白矩阵的唯一入口”。
- **运行清晰**：有固定 `in/tmp/out/logs/meta` 结构、最小重启单元、day/week 节奏。
- **工具可换**：R 包、具体归一化/插补方法都挂在 toolbox 层，以后要换方法只改函数实现。
- **可迁移**：你以后做别的项目（phospho、TMT、多组学），Quant stage 的骨架可以照搬，只调 I/O 合约 & 参数。

------

如果你愿意，下一步我们可以选一个点**直接落地实现**，比如：

- 设计 `ProteinMatrix` / `ProteinStats` 的 **精确列名 + 类型规范**；
- 或者把 `filter_protein()` 的规则写成清晰的 R 实现（含边界情况）；
- 或者先写好 `meta.json` 的 `StageMeta` Python 工具类，让所有 stage 通用。

你可以随手选一个，说：“我们先把这个写掉。”

