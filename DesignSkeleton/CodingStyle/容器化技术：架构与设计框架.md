# 容器化技术：架构与设计框架

## Whitepaper v1.0 · 作者：张富卿方向体系

------

![](https://media.geeksforgeeks.org/wp-content/uploads/20240313181625/Containerization-Architecture.webp)

![](https://www.cherryservers.com/v3/assets/blog/2022-12-20/01.jpg)

![](https://www.cloud-kinetics.com/wp-content/uploads/2023/06/image3-1.png)

### 前言：环境应该被视为“工件”而不是“运气”

当今的大部分工程问题，从生信到机器学习，从云流程到分布式系统，都被一个隐藏变量影响着：

> 环境。

它不被版本化、不被建模、不被抽象，只能靠“运气、经验、Penicillin 操作、群聊问答”维持。
 而容器技术的意义，就是把“环境”本身从隐变量变成 显式工件（Environment Artifact）。

你已经把 heatmap、GWAS pipeline、数据处理流程做成了“形式化结构”。
 本白皮书希望把你未来十年的工程体系的核心设施——容器，也建模到同样的高度。

------

### 

### 1. 第一性原理（First Principles）

#### 容器是什么、为什么存在、应该怎样被设计

------

#### 1.1 容器本质是什么？

容器不是 package manager、不是虚拟机、不是可爱的技术玩具。

它本质是：

> 由操作系统裁剪出的“可执行环境切片”
> （Executable Environment Slice）

它包含：

- OS + glibc（决定二进制能否运行）
- runtime（R / Python / C++ / system）
- 所有依赖（arrow、data.table、plink2…）
- 入口（entrypoint）

并且它是：

- 不可变（immutable）
- 版本化（tag）
- 可迁移（pull anywhere）
- 可复现（reproducible）

容器 = 环境的 可执行快照（snapshot）。

你过去试图靠 micromamba + renv 管环境，但始终逃不掉宿主机 glibc 的约束。

容器解决的是根层问题。

------

#### 1.2 容器为什么存在？（存在理由）

容器并不是为了“更方便安装软件”，它的存在理由来自三个“工程级痛点”：

##### 1) 宿主系统不可控（你遇到的 Arrow/glibc 是典型）

- CentOS 8 glibc 2.28
- Arrow 14 想要 glibc ≥ 2.32
- 宿主 OS 一锁死，你就永远装不了最新版的 R/Python/Arrow。

容器让你绕开宿主 OS：

> 你想用的工具，不再依赖宿主系统能否配合。

------

##### 2) 环境无法复现，迁移困难

你现在的 after_sales / PWAS / proteomics 项目都有：

- “在哪台机跑都不一样的环境”
- “重装系统后所有脚本都炸”
- “环境变成一个会腐烂的生物体”

容器让环境可复制：

> 镜像 = 你的环境 DNA，永不腐烂。

------

##### 3) 工具链碎片化，流程不能标准化

你现在遇到：

- R 版本不同 → 画图不同
- Python 版本不同 → polars 行为不同
- HPC 上一台机器是 libcurl 7.29，一台是 7.88
- 云平台要规范，但开发者电脑各自一套

容器给一个“统一构建协议”：

> 流程 =（代码 + 镜像 + 配置）这三件事的组合。

这三点才是容器的“必要性”，不是 hype。

------

### 

### 2. Atomic Decomposition：容器世界的原子（Atoms）

和 heatmap 的原子体系一样，我们对容器做原子化拆解：

##### 2.1 Filesystem Atom (F)

容器内最重要的“世界”：

- OS + glibc
- R 4.5 / Python 3.14
- Arrow / data.table / polars
- 字体 / locale / cli tools
- 你的脚本

它是“不可变”的。

------

##### 2.2 Process Atom (P)

容器中只有 一个“主进程”：

- `Rscript main.R`
- `python run.py`
- `/usr/bin/plink2`

容器生命周期 = 主进程生命周期。

------

##### 2.3 Namespace Atom (N)

隔离世界：

- PID namespace
- mount namespace
- network namespace
- user namespace

避免污染宿主机。

------

##### 2.4 Config Atom (C)

运行时注入：

- 环境变量
- volume 挂载
- CPU / memory 限制
- 参数

同一镜像，通过 Config 变化成不同实例。

------

##### 2.5 Interface Atom (I)

你必须固定的：

- 输入目录（`/work/in`）
- 输出目录（`/work/out`）
- CLI flag 名称

这是流程与工具交互的契约。

------

##### 2.6 Data Atom (D)

容器看到的数据：

- 宿主机绑进 `/work` 的真实文件

整个 pipeline 的数据流靠 Data Atom 传递。

------

### 

### 3. 容器的 Layer Architecture（分层架构）

![](https://www.researchgate.net/profile/Feras-Awaysheh-2/publication/353162654/figure/fig2/AS:1045045734014976@1626169727373/Docker-layered-architecture-and-hypervisor-vs-container-virtualization-abstraction.ppm)

![](https://miro.medium.com/v2/resize%3Afit%3A1302/1%2AysjmUDrKKkr4eY0YpID5rA.jpeg)





容器体系是多层的，每层有清晰职责：

------

##### 3.1 宿主层（Infra Layer）

- CentOS / Ubuntu / Rocky
- HPC / Slurm / 云 / 裸机
- 无法更换 glibc（你现在的痛点）

容器的任务就是“屏蔽”它。

------

##### 3.2 运行时层（Runtime Layer）

- Docker
- Podman
- Singularity / Apptainer
- containerd

提供 namespace + cgroup 隔离。

------

##### 3.3 镜像层（Image Layer）

镜像叠加结构：

1. Base OS（rocky/ubuntu minimal）
2. Language Base（R-4.5 / Py-3.14）
3. Tool Layer（arrow, data.table, tidyverse…）
4. Pipeline Layer（你的 R/Python 工具链）
5. Entrypoint

------

##### 3.4 Workflow 层

- WDL
- Nextflow
- Snakemake
- 自家云平台

每个 task/process 指定不同镜像 → 组合复杂流程。

------

##### 3.5 Orchestration 层

- Slurm
- Cromwell
- Kubernetes
- Nextflow runtime

把镜像调度到节点执行。

------

##### 3.6 Ops 层

- 镜像仓库（Harbor / GitLab / GHCR）
- 镜像 tag 策略
- 清理策略
- 镜像依赖监控

工程体系真正能“跑十年”的关键。

------

### 

### 4. 最小粒度（Atomic Unit）：容器应该怎么拆分？

这是你刚刚问的核心问题：“R-base 与 R 包环境容器如何切分？”

答案：

> 以“稳定度”作为分层原则，以“工具族（tool family）”作为最小容器单位。

这是行业标准，也是你工程体系最稳健的划分方式。

------

### 

### 5. 容器的切分规则（极其关键）

下面正式回答你刚刚问的那个第二个问题。

#### 

#### 5.1 切分原则：稳定向下，易变向上

把整个镜像拆成 3 大层：

##### Layer 1：Language Base（稳定，不应频繁重建）

例如：

- `fq-r-base:4.5`
- `fq-py-base:3.14`
- `fq-rust-base:1.81`

内容：

- OS
- glibc
- runtime（R/Python）
- 基础系统依赖（curl, openssl, fontconfig…)
- 字体（SimSun, Noto Sans 等）

特点：

- 重建成本高
- 稳定性要求高
- 一变会影响所有上层镜像

重建频率：
 1–3 个月一次（或语言版本更新时）

------

##### Layer 2：Tool Layer（任务族相关的软件包集合）

根据任务类型拆：

- `fq-r-plot:2025.01`
    - ggplot2、ggh4x、openxlsx、gridtext、arrow、data.table
- `fq-r-gwas:2025.01`
    - plinkr / matrixEQTL / data.table / your pipeline libs
- `fq-py-gwas:2025.01`
    - numpy, polars, pyarrow, cyvcf2

原则：

> 同一个“任务族”的包放一个 Tool Layer，不同任务族分不同镜像。

重建频率：
 1–2 周，或当工具升级时

------

##### Layer 3：Pipeline Layer（具体流程的脚本 + 入口）

例如：

- `fq-pipeline-after_sales:2025.01`
- `fq-pipeline-proteomics:2025.02`
- `fq-pipeline-pwas:2025.01`

内容：

- 你的 R/Python 脚本
- 配置文件模板
- ENTRYPOINT

特点：

- 非常频繁修改
- 若设计良好，可以极薄（只复制脚本 + entrypoint）

------

### 

### 5.2 为什么不能只做一个“大 R 镜像”？

因为：

- 一变所有流程一起崩
- 镜像会膨胀到几十 GB
- 更新速度慢
- 不可复用
- CI/CD 成本巨大

你需要的是：

> “稳定 OS + 最新语言 + 中层工具族 + 极薄 pipeline 层”
> 这是现代云原生的正统架构。

------

### 

### 5.3 如何判断 R 包应该放在哪层？

这是你最需要的明确规则，我给你一个总结版决策树：

------

#### 决策树：

##### Step 1：这个包是否属于“语言运行时级别依赖”？

例如：

- data.table
- Rcpp
- openssl
- curl
- arrow
- glue
- vctrs

这些包是所有工具链都要用的，
 放 Language Base。

------

##### Step 2：这个包是否是某个“任务族”范围内的？

例如：

- ggplot2（画图族）
- ggh4x / patchwork（画图族）
- MatrixEQTL（GWAS/pQTL 族）
- limma / msqrob（蛋白质组族）

放 Tool Layer。

------

##### Step 3：这个包只被某个 pipeline 用？

例如：

- 专门为 after_sales 写的自定义包
- 专门为 report 用的内部 package

放 Pipeline Layer。

------

### 

### 5.4 你最推荐的镜像体系示例（基于你的工作内容）

##### Base 层：

- `fq-r-base:4.5`
- `fq-py-base:3.14`

##### Tool 层：

- `fq-r-plot:2025.01`（绘图/报表）
- `fq-r-gwas:2025.01`（GWAS/PWAS）
- `fq-r-proteomics:2025.01`（DIA/MS 数据处理）
- `fq-py-gwas:2025.01`

##### Pipeline 层：

- `fq-pipeline-after_sales:2025.01`
- `fq-pipeline-proteomics:2025.02`
- `fq-pipeline-gwas:2025.03`

这就是你未来几年整个工程体系的标准形态。

------

### 

### 6. Container Engineering Pattern（六步工程法）

以后你开发任何工具，都按照这 6 步走：

1. 定义 I/O 和 CLI
2. 选择 base-layer（R/Python）
3. 构建 tool-layer（任务族包）
4. 构建 pipeline-layer（脚本 + entrypoint）
5. 本地 build + run
6. push 到 registry（像 git push 一样）

完成即成为一个可移植、可复现、可调度的“工具单元”。

------

### 

### 7. 演化路线图（Roadmap）

未来半年你的路线可以是：

- 周期 1：构建 base 镜像
- 周期 2：拆分 tool families
- 周期 3：把 after_sales → container 化
- 周期 4：把 PWAS/GWAS 主线 → container 化
- 周期 5：统一 I/O 协议
- 周期 6：统一 workflow API（WDL/Nextflow）

最终目标是：

> 任何流程 = 镜像 + 配置
> 环境成为“工程资产”，不再是隐形风险。

------

如果你愿意，我可以继续写：

- 图示版（像 heatmap 那样）
- 一个典型 R-4.5 / Python-3.14 容器体系的完整示例
- 你公司未来一年容器化路线图的规划
- 你的 GWAS/PWAS 项目如何一步步迁移到容器体系
- 如何设计 container registry 的 tag 策略

你下一步想让我写哪部分？

------

能抽象为「纯函数库」的部分 → 进 toolbox-r / toolbox-py；

带具体数据格式、I/O 协议、参数约定的部分 → 留在 plot_ / pipeline 模块，作为 CLI / 任务入口；

容器镜像对外暴露的，是这些 CLI；
 内部依赖的，是 toolbox 库。

对，你这段话已经踩到点子上了，我帮你再“压缩成公理”：

------

#### 1. 先回答：你理解得对不对？

基本对，而且是我最推荐的路线。

- plot_ 系列：

    - 把“真正有价值的绘图逻辑”——比如数据整形、颜色映射、facet 规则、主题、坐标轴处理——
        抽成一个个函数，集中进 `toolbox-r`（一个 R 包）。
    - 每个项目自己写自己的 `plot_\*` 封装：
        - 这些封装只做：
            - 解析参数
            - 读入各自项目的数据格式
            - 调用 `toolbox-r::plot_xxx()`
            - 输出 pdf/png/svg

    👉 项目之间不再同步 plot_ 目录，而是同步 toolbox-r。

- annotation、enrichment 等核心逻辑：

    - 把“不依赖具体项目目录结构 / 文件命名 / 业务文案”的那部分逻辑，
        抽成 `toolbox-py` 里的函数：
        - 比如：`run_ora()`, `prepare_bg_fg_gene_sets()`, `parse_gaf()`, `decorate_enrich_result()` 等。
    - 各项目自己的 `annotation/cli.py`, `enrichment/cli.py` 只是包装层：
        - 解析 CLI 参数；
        - 根据自己项目的路径约定读取输入；
        - 调 `toolbox_py.enrichment.run_ora()`；
        - 把结果写成项目要求的 Excel/tsv/json。

    👉 项目之间不再同步 annotation/enrichment 目录，而是同步 toolbox-py。

所以是你说的这句：

> 将来再各项目间同步的，可以说永远只有 toolbox-r、toolbox-py

对，把“跨项目同步”这件事，收缩到这两个 toolbox，就对了。

------

#### 2. 稍微补充一点细节：有两个层次的“复用”

你可以这样记：

1. 库级复用（真正的核心资产）
    - `toolbox-r`: R 里的 plot/enrich 硬核函数
    - `toolbox-py`: Python 里的 io / 调度 / enrichment 核心算法
    - 这些通过：
        - R：`library(toolboxR); plot_manhattan(df, cfg)`
        - Py：`from toolbox_py.enrich import run_ora`
    - 只要换项目，只要 import 同一个 toolbox，逻辑一致。
2. 工具级复用（CLI 层，可选）
    - 你也可以把现在的 `plot_bar`, `plot_point` 这种 CLI 封装，设计得足够通用，让多个项目直接复用同一套 CLI；
    - 但这不是强制的：每个项目可以在自己的仓里写一个更贴自己需求的 plot_ 包装，只要内部都调向同一个 toolbox-r 函数，就不会产生“多套逻辑”。

所以真正要坚定的是两个原则：

- 跨项目复用，优先落在 toolbox（函数层），不是脚本层。
- 脚本（plot_ / annotation / enrichment 模块）可以相似，但不一定要强行共用；
    共用的是它们背后的 toolbox。

------

#### 3. 为什么这样做会让后面“容器 + 多项目”都好过很多？

因为一旦你把“共用逻辑”收缩到两个包：

- 环境层面：
    - `toolbox-r` → 在 R 容器里预装；
    - `toolbox-py` → 在 Python 容器里预装；
    - 以后任何项目，只要用你的容器，就自动拥有这些能力。
- 代码层面：
    - 项目仓库只需维护“本项目的 CLI + pipeline glue”；
    - toolbox 的版本升级有自己节奏（`v0.1.0 → v0.2.0`），项目显式依赖某个版本。
- 协作层面：
    - “我修了一版更好的 Manhattan 图逻辑” → 改 toolbox-r，发新版本；
    - 所有项目只要 bump 一下依赖版本，就能用到新的画法。

你就从“每个项目一套 plot_ 地狱”升级成：

> 一个 toolbox-r / toolbox-py 生态，
> 多个项目像插件一样挂在上面。

------

#### 4. 小小提醒：别着急强迫所有现有东西入 toolbox

实践上可以分两步走：

1. 先在现有仓库内部，把“可以抽的逻辑”集中到 `toolbox_r` / `toolbox_py` 命名空间里（还不急着拆库）；
2. 等你感觉 API 稳定、重复利用几次之后，再正式做成独立仓库 + 版本管理 + 容器层预装。

否则一开始把 everything 丢进 toolbox，等于把“还没想好的东西”也刻在石头上，会拖住你。

------

一句话总结你刚才的理解：

> 对，以后跨项目共享的不是一堆散装 plot_ / annotation 目录，而是一对精炼的 toolbox-r / toolbox-py，其他东西都只是“当前项目怎么调用它们的包装层”。

#### 一、把 toolbox 当成“标准库”，不是“工具堆”

第一原则：

> toolbox = 你自己世界里的 standard library
>
> 业务脚本可以乱一点，toolbox 不行。

你可以直接给自己定一个认知：

- `src/plot_.../src`：允许试验、允许写粗糙一点；
- `toolbox-r` / `toolbox-py`：必须符合“标准库级别”要求。

那问题变成：什么样的东西够格晋升成标准库？

------

#### 二、晋升规则：只有“过关代码”才能进 toolbox

给你一个可执行的晋升 checklist：

##### 1. 多处使用（复用证明）

硬规则，可以叫 3 次使用原则：

- 同一逻辑在至少两个不同子模块里使用过（比如 plot_bar + plot_point 都用到 facet/主题）；
- 或者：同一项目里不同上下文调用过至少 3 次；

才考虑抽到 toolbox。

> 一次性逻辑 → 留在项目脚本；
> 多处重复 → 才有抽象价值。

------

##### 2. 与具体项目解耦

只有满足以下条件，才能进 toolbox：

- 不依赖具体路径结构（比如不直接写 `../share/fonts`）；
- 不硬编码项目名/物种名/客户名/渠道名；
- I/O 尽量用参数 + data.frame/df，而不是直接读写项目路径。

例如：

❌ 不能进 toolbox 的：

```
plot_manhattan_for_barley <- function() {
  df <- readr::read_tsv("out/barley_gwas_result.tsv")
  ### ...
}
```

✅ 可以进 toolbox 的：

```
plot_manhattan <- function(df, cfg = list()) {
  ### 只对 df 内容和 cfg 负责
}
```

项目层负责：

```
df <- readr::read_tsv("out/barley_gwas_result.tsv")
p <- fqPlotR::plot_manhattan(df, cfg)
```

------

##### 3. 接口清晰、参数不屎山

如果一个函数要进 toolbox，接口要满足：

- 参数数量适中（>7 个就要小心）；
- 不堆一大坨 bool 参数（`if_plot_title`, `if_plot_legend`, …）；
- `cfg` 类参数最好是结构化列表，而不是 20 个平铺参数。

简单记一个红线：

> 如果为了兼容三个项目的不同需求，你在函数里堆了十几个 if/else，
> 那它还不配进 toolbox，它的抽象还没长大。

------

##### 4. 有最小测试 / 最小例子

不需要一上来就完美单测，但至少要做到：

- toolbox-r：
    - 有一个 `tests/testthat/` 下的测试，能跑至少一个完整调用；
    - 或者一个 `inst/examples/` 下的 demo 脚本可以被自动跑一次；
- toolbox-py：
    - 有最基本的 `pytest` case / golden file 测试。

这保证你：

- 将来重构时有东西帮你兜底；
- 容器里升级 toolbox 时，不会一脚踢崩所有项目。

------

##### 5. 有一句话级别的设计说明

对每个进 toolbox 的函数 / 模块，用一句人话写清：

- 它负责什么；
- 不负责什么；
- 有哪些已知限制。

这句话写对了，说明你的抽象想清楚了；
 写不出来，就别进 toolbox，继续在项目脚本里滚一阵子。

------

#### 三、你可以采用“孵化区 → 正式库”的两级机制

为避免“半成熟代码一进入 toolbox 就石化”，可以弄一个过渡区：

##### 1. 在 toolbox 里加一个 `experimental` 命名空间

比如：

- R: `R/experimental-manhattan.R`
- Py: `toolbox_py/experimental/manhattan.py`

规则：

- `experimental` 里的 API：
    - 可以频繁改名；
    - 可以随时砍掉；
    - 文档明确写“实验性”。

##### 2. 晋升流程（很具体）：

1. 在项目脚本里发现重复逻辑 → 提炼成函数 → 先放入 `experimental`；
2. 至少被两个模块 / 两个项目使用 + 自己用了几次还满意；
3. 给它写测试 + 写一句话描述；
4. 从 `experimental` 移到正式命名空间：
    - R: `R/manhattan.R`
    - Py: `toolbox_py/enrichment/manhattan.py`
5. 为这个 API 打一个版本号（在 CHANGLOG 或 NEWS 里登记）。

你可以理解为：

> `experimental` = 训练场；
> 正式命名空间 = 正式选手登记册。

------

#### 四、结合你现在的 gwas 结构，给一条实际落地路径

你现在可以做的 最小动作：

##### 1. 在现仓里加清晰 toolbox 命名空间（不拆库也行）

- `src/toolbox_py/`
- `src/toolbox_r/`（或者一开始就用 R package 结构）

##### 2. 把你觉得“八成会复用”的逻辑，先搬到 `toolbox_* / experimental` 里

例如：

- Manhattan 图核心数据处理；
- 统一的主题 / 颜色映射；
- enrichment 的 ORA 胶水逻辑；
- 一些基于 arrow/parquet 的 IO helper。

只做轻度搬运，不改逻辑。

##### 3. 强制新代码优先调用 toolbox，而不是复制逻辑

以后你写新 plot/enrichment 模块时，优先想：

- 有没有可以复用的 toolbox 函数？
- 如果没有，这段逻辑是不是有潜力以后复用？如果有 → 写得像 future toolbox 那样，而不是随便糊。

##### 4. 每隔一段时间做一次 “toolbox 评价日”

比如每月/每两周，回看：

- 哪些 experimental API 被用了多次、长得比较稳定；
- 哪些 experimental API 已经证明是垃圾（没人用 / 抽象失败）→ 干脆删掉；
- 哪些可以晋升到正式命名空间。

这相当于你给 toolbox 设计了一个“自然选择机制”。

------

#### 五、最后帮你压成一条判断准则

以后你犹豫：“这东西要不要放 toolbox？”
 就在脑子里过一遍：

1. 多处使用了吗？
2. 跟具体项目路径 / 客户 / 表头耦合了吗？
3. 函数签名干净吗，还是写成 if-else 地狱？
4. 有最小测试 / 最小 demo 吗？
5. 我能不能用一句话说清它“负责什么 / 不负责什么”？

五个里有两个过不去，就先别放 toolbox。

##### 2.1 镜像分层，而不是 venv 分层

Layer 1：bio-cli 镜像（基础 CLI 工具层）

- 镜像名：`fq-bio-cli:2025.01`
- 内容：
    - OS（Rocky / Ubuntu）
    - bcftools, samtools, plink2, emapper.py, bgzip, tabix …
    - 这些工具放在 `/usr/local/bin` 或 conda env 的 bin 中；
- 职责：
    - 提供“稳定、版本明确”的 CLI 工具集；
    - 不一定要有 Python。

Layer 2：toolbox-py 镜像（FROM bio-cli，加 Python）

- 镜像名：`fq-toolbox-py:2025.01`

- Dockerfile：

    ```
    FROM fq-bio-cli:2025.01
    
    ### 安装 Python 3.14 + pip / micromamba / pdm
    ### 或者直接 conda-forge python=3.14
    RUN micromamba install -n base -c conda-forge python=3.14 ...
    
    ### 安装 toolbox-py 及依赖
    RUN pip install toolbox-py==0.1.0
    ```

- 职责：

    - 提供：toolbox-py + CLI 工具（继承自 fq-bio-cli）；
    - 你的 gwas / annotation / enrichment 程序就在这个镜像里跑。

重点：

> CLI 工具和 Python 脚本在同一个环境里跑，
> 只是“逻辑上”分成 `toolbox_py.cli` / `toolbox_py.core` 这种层次。

不会天然变得庞杂，只有在你把 toolbox 当垃圾桶，它才会变成垃圾桶。
 你这个担心是对的，但解决方案不是“把共用 CLI 调用逻辑排除在 toolbox 之外”，而是——精细划分 toolbox 内部的层级和“入库标准”。

我直接给结论：

> ✅ 共用的 CLI 调用函数是可以进 toolbox 的，但必须进专门的“CLI 集成层”命名空间，而不是和纯 Python 核心逻辑混在一起。
> ❌ 只要是“带强项目气味、目录/文件名/业务习惯”的 CLI 封装，就不要进 toolbox，即使你现在觉得“反正也会共用”。

下面把这个说细一点。

------

#### 1. 先把 toolbox_py 里你真正要的东西拆成三圈

不然“庞杂/不庞杂”这话永远说不清。

##### 圈 1：core 层（纯逻辑）——toolbox 的黄金心脏

- 不依赖 subprocess，不跑外部命令；
- 输入输出就是 Python 对象（DataFrame、dict、list…）；
- 比如：
    - `normalize_p_values(df)`
    - `compute_ld_blocks(df_genotype)`
    - `prepare_manhattan_df(df_gwas)`
    - `load_parquet_table(path, cols=None)`

👉 这层是你将来最值钱的部分，也是 "永远值得进 toolbox" 的东西。

------

##### 圈 2：runner / shell 层（通用子进程调用能力）

- 这层不关心 emapper / bcftools 是谁，只处理：
    - 如何跑一个外部命令；
    - 如何记录 log；
    - 如何设定超时 / 捕获错误 / tail 输出；
- 比如现在的 `run_step()`、`run_jobs()` 就属于这一层。

👉 这层本质是“基础设施”，可以放在 `toolbox_py.runner` / `toolbox_py.shell`，
 肯定应该在 toolbox，因为所有项目都要用它。

------

##### 圈 3：tools 集成层（对具体 CLI 工具的“通用封装”）

- 专门用来封装 emapper, bcftools, plink2, samtools 这种东西；
- 原则是：
    - 不知道项目名称；
    - 不知道 GWAS/PCQ/哪种 pipeline；
    - 只关心“给我参数，我在某个目录里帮你跑一次工具，并告诉你输出在哪”。

例如：

```python
### toolbox_py/tools/emapper.py
def run_emapper_search(...): ...
def run_emapper_annotate(...): ...

### toolbox_py/tools/bcftools.py
def bcftools_view(...): ...
def bcftools_filter(...): ...
```

👉 这层可以进 toolbox，但必须放在清晰的 namespace 里：`toolbox_py.tools.*`，
 而不是乱塞进 `core`。

------

#### 2. 什么东西「不能」进 toolbox（即便它是“共用”的）

这一条要说死：

> ✅ “通用工具 ➜ 多项目复用 ➜ 与具体目录结构/业务耦合低” → 可以进 toolbox。
> ❌ “只是同一个项目里多处复用的具体业务逻辑” → 不要进 toolbox。

比如下面这种（典型错误）：

```python
def run_emapper_for_gwas_cohort(...):
    dir_root = dir_tmp / "annot_emapper" / "_cohort"
    ### …里面顺便帮你按 GWAS 项目的目录命名规则创建 tmp/out/logs
```

它有这些问题：

- 硬编码了 `_cohort`、`annot_emapper`；
- 假设输出结构是你现在这个 gwas 项目的那种；
- 换个项目肯定又得重新写一遍。

这种函数，即使被你在 gwas 项目里多次调用，也不配进 toolbox。
 它顶多配进当前项目的 `src/services/annotation_emapper.py` 之类的模块。

所以你要做到的是：

- 把“纯粹调用 emapper 一次 search 的逻辑”抽象到 `toolbox_py.tools.emapper.run_emapper_search()`；
- 把“用 emapper 为 gwas 某个 stage 服务”的那部分 glue，留在项目仓库里。

------

#### 3. “toolbox 会不会越来越大？”——可以，但要“有秩序地大”

大不大不是问题，乱不乱才是问题。

给你一个推荐结构，保证大而不乱：

```text
toolbox_py/
  __init__.py

  core/               ### 纯 Python 逻辑，最核心
    __init__.py
    io_parquet.py
    stats_enrich.py
    gwas_ld.py
    plotting_core.py

  runner.py           ### 通用子进程调用、日志、超时

  tools/              ### 对 CLI 工具的通用封装
    __init__.py
    emapper.py        ### emapper 相关
    bcftools.py       ### bcftools 相关
    plink2.py         ### plink2 相关
    samtools.py       ### samtools 相关

  experimental/       ### 试验区（以后满足条件再晋升）
    __init__.py
    new_weird_algo.py
```

调用方式：

- 项目逻辑：

    ```python
    from toolbox_py.core.io_parquet import read_parquet_table
    from toolbox_py.tools.emapper import run_emapper_search
    from toolbox_py.runner import run_step
    ```

- 任何新项目，只要装了 `toolbox_py`，就可以用这些东西，它们的行为是统一的。

🧠 关键点：

- core：纯逻辑，越精越好；
- runner：infra；
- tools：CLI 封装，但每个文件只负责一个工具家族；
- experimental：还不确定的东西，先不要放到 core/tools 里。

有了这样的布局，toolbox 可以长，但不会变成一锅粥。

------

#### 4. 用“晋升制度”控制 CLI 封装是否进 toolbox

你说得对，“业务理解不够、抽象不够，就急着塞 toolbox”，最后只会制造新屎山。

我们可以对「CLI 封装是否进入 toolbox」定个硬规则：

只要有一个不满足，就暂时留在项目里，不进 toolbox：

1. 是否跟某个项目强耦合？

    - 用了固定子目录名（`_cohort`、`pcq_2025` 之类）？
    - 假设了特定文件名 / 前缀？
        🔺 有的话 → 不进 toolbox。

2. 是否能用“通用模型”描述？

    - 比如：emapper 的封装，你能说清：

        > “输入：FASTA、数据库目录、输出根目录；
        > 输出：seed_orthologs 路径、hits 路径、log。”

    - 如果说不清，只能描述成“给当前项目跑一下 emapper 那段”，那它还没长大。

3. 是否有至少两个项目 / 两个场景想用？

    - 只有这一个项目需要 → 先别升 toolbox；
    - gwas、pwas、另一条 pipeline 都要用 → 可以考虑进 toolbox。

4. 函数签名是否干净？

    - 一堆 bool 开关：`if_for_barley`, `if_for_cotton` 这种 → 说明你抽象失败；
    - 参数 20 个、各种选填 + 魔法默认 → 不配进 toolbox。

你可以把这个当“共用 CLI 封装晋升规则”，写进自己未来的开发守则里。

------

#### 5. 直接给你一句可以挂在脑子里的原则

> toolbox 里可以有 CLI 封装，但它们必须是“对具体工具的通用适配层（tools/\*）”，
> 而不是“对某个项目的业务脚本”。
>
> 只要是带项目味道的 CLI 调用，再“共用”也只留在项目仓库，
> toolbox 只收：抽象干净的 core + tools + runner。

这样做，你的担心就会自动消解：

- toolbox_py 会越来越强，但不会越来越乱；
- CLI 封装不会泛滥成灾，因为有进入标准；
- 将来任何项目只要依赖 toolbox，就自然继承你过去所有抽象成果。

------像 + 用 toolbox 调。
